Overview and state of Linkerd: QZDQ-6245 - events@cncf.io - Thursday, November 19, 2020 4:52 PM - 44 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi there. My name is William Morgan.
00:00:02 [W] very fresh linkerd e 2.9 release and our plans for 2.10 and Beyond by the way to ruin started his linkerd e Journey as a Google summer of code student and now he holds the illustrious title of linkerd e maintainer, so hopefully he'll tell you
00:00:17 [W] But before that I'm going to give you an introduction to linkerd e What It Is What It Isn't and then I'll hand it over to tarun.
00:00:22 [W] So here we are.
00:00:23 [W] What is linkerd e linkerd e is a servicemeshcon.
00:00:25 [W] That's a term that you have heard before but it's okay if you haven't because I'm going to tell you what that means linkerd e is known as an ultra-light and Ultra fast and Security First servicemeshcon go into you details for each of those.
00:00:40 [W] Aspects of linkerd e very healthy community of adopters and contributors of which you are now officially members by watching this talk you are now part of the linkerd E community so welcome.
00:00:52 [W] It's very nice to have you here over four years in production slack Channel with 5,000 members in it, very helpful and friendly members all sorts of GitHub stars and and contributors. And of course were hosted by
00:01:08 [W] All sorts of fancy logos up here to to logos up here that are not up here that probably should be because we have two very exciting end-user talks at this very conference one of the keynote by Dave sutiya of go
00:01:14 [W] Talks about how he uses linkerd e and other cncf projects to build a developer platform at go spok check the definitely go watch that talk and then another exciting talk from Justin Turner
00:01:25 [W] and then another exciting talk from Justin Turner and Garrett Griffin at HEB talking about how they rolled linkerd e out to production in order to accelerate the delivery of their curbside check out H-E-B the grocery store in
00:01:40 [W] The covid-19 pandemic so linkerd e is not just a cool project can actually help people, you know get their groceries as part of the pandemic. So that is really exciting for us.
00:01:52 [W] Be sure to take out those check out those two talks.
00:01:54 [W] So let's get back to linkerd e what does linkerd e do so as a servicemeshcon?
00:02:10 [W] There's and there's some nice screenshot here of the cool dashboard that we have as well.
00:02:16 [W] And what's interesting about the servicemeshcon.
00:02:18 [W] My mind is that it's thought that these are new features that we've never had before.
00:02:22 [W] It's that what the servicemeshcon is what linkerd e does is it gives you these features at the platform level?
00:02:28 [W] So rather than having the developers have to implement things like TLS or retries or timeout or metrics, of course, they still
00:02:40 [W] To do some of that right?
00:02:44 [W] there's still a component to reliability and security and observability that cannot be done by the servicemeshcon rather than the servicemeshcon developers having to own all of that.
00:02:53 [W] They can now get those features at the platform level.
00:02:57 [W] So that's what linkerd e provides it moves us features out of the hands of the developers and down to the platform where they belong
00:03:04 [W] And what's interesting about the servicemeshcon my mind is that it's thought that these are new features that we've never had before. It's not what the servicemeshcon does when linkerd e does is it gives you these features at the platform level?
00:03:16 [W] So rather than having the developers have to implement things like TLS or retries or timeouts or metrics. Of course, they still have to do some of that right
00:05:13 [W] Simple so why should you care? Well in my mind you should care because what linkerd he does is it gives you the platform owners the kubernetes adopters, the s.res gives you some Primitives around observability and security and
00:05:28 [W] But you need you need these things. If you're building a cloud native application and it does it in a way.
00:05:33 [W] Like I said that gives, you know developer involvement.
00:05:36 [W] So it's not really about solving technical problems so much as solving socio technical problems.
00:05:41 [W] It's going to give you the control and ownership over your own destiny.
00:05:45 [W] Sounds great.
00:05:47 [W] Okay, let's talk a little bit about linkerd.
00:05:49 [W] He's design philosophy in short.
00:05:51 [W] I would say this is do as little as possible.
00:05:54 [W] Right? So linkerd e should just work out of the box.
00:05:58 [W] You should be able to add linkerd e to a functioning kubernative application and the application should continue functioning.
00:06:04 [W] Okay.
00:06:05 [W] Sounds great. Actually pretty hard to do should consume as a minimum of resource costs, right?
00:06:12 [W] So memory CPU consumption should be as small as possible the latency that in-toto
00:06:17 [W] Adds, your application of course should be as small as possible to and there's all sorts of cool engineering that we do in order to accomplish that it should be simple.
00:06:26 [W] So you as the operator of linkerd e should not have to wrestle with a thousand configuration options and a whole bunch of new Jama land and so on you've just adopted kubernative.
00:06:36 [W] He's already very complicated. You shouldn't have to adopt a whole new level of complication and linkerd E should have security enabled out of the box on by default and that's a big headline feature of 2.9.
00:06:47 [W] Nine around usual TLs, but I'll leave that for to room.
00:06:52 [W] All right. So linkerd e should just work out of the box.
00:06:56 [W] You should be able to add linkerd e to a functioning kubernative application and the application should continue functioning.
00:07:01 [W] Okay.
00:07:02 [W] Sounds great.
00:07:03 [W] Actually pretty hard to do.
00:07:04 [W] It should consume as a minimum of resource costs, right?
00:07:10 [W] So memory CPU consumption should be as small as possible the latency that it adds your application of course should be as small as possible to and there's all sorts of cool engineering that we do in order to accomplish that
00:07:21 [W] That it should be simple.
00:07:24 [W] So you as the operator of linkerd e should not have to wrestle with a thousand configuration options and a whole bunch of new Jama land and so on you've just adopted kubernative.
00:07:33 [W] It's already very complicated.
00:07:35 [W] You shouldn't have to adopt a whole new level of complication and linkerd E should have security enabled out of the box on by default. And that's the big headline feature of 2.9 around Mutual TLs, but I'll leave that for tarun. So if
00:10:12 [W] To talk a little bit about called linkerd E2 - proxy and I have you know some background reading here if you feel like hearing about some of the history in the big kind of rewrite from linkerd E V1 to V2.
00:10:27 [W] All right, so just briefly linkerd e architecture like most servicemeshcon.
00:10:30 [W] So there is a control plane and there's the data plane the control plane.
00:10:34 [W] There's a bunch of components that set off to the side and give you control and visibility into the data plane. And the data plane is a set of proxies those proxies are deployed deployed as sidecar containers, which means they sit in the same POD at your application
00:10:49 [W] Could he does all the magic to make the TCP connections to your to and from your application components go through those proxies so that the proxy can handle all the fancy stuff that needs to handle it can initiate and terminate
00:11:04 [W] And change HTTP one to http 2 and so on.
00:11:06 [W] and ideally that happens under the scenes without your developers being aware of it without them even having to know that linkerd e is there now you might have noticed in that diagram that there are two proxies that we've added in between every single hop, so that means
00:11:21 [W] To be really really fast and really really lightweight because you might have a whole lot of them.
00:11:23 [W] So we have invested a whole lot of time and energy into what we call our micro proxy, which is a linkerd e data plane called linkerd E2 proxy.
00:11:33 [W] It's a critical part of the system many service measures are built on Envoy.
00:11:36 [W] We're not we are built on this very dedicated servicemeshcon seat, which allows us to be extremely fast extremely low memory and extremely secure. So by writing this in Rust we avoid a whole class of men.
00:11:48 [W] Revolver abilities that are endemic to cncf LS plus we can be, you know, just as fast as the machine will let us be of course--we're audited thanks to cncf. We have regular third party security audits which we pass
00:12:03 [W] Cody to proxy is built on this ultra-modern asynchronous network stack.
00:12:05 [W] So all of the really interesting asynchronous Network programming kind of development is all happening in the rust world today.
00:12:12 [W] So if that kind of thing is exciting to you then please check out the repo. Everything is open source, of course Apache be 200% audited hundred percent. Awesome. That's linkerd.
00:12:24 [W] E2 - proxy. Here's a little snippet from the security audit Force the full
00:12:29 [W] Audit is in the repo itself a typically excellent code readability careful choice of implementation languages.
00:12:37 [W] Yeah.
00:12:38 [W] It was a good report.
00:12:38 [W] Okay.
00:12:40 [W] We actually have a newer version of these numbers.
00:12:45 [W] Unfortunately that newer version was not available in time for me to record this. But if you search for convoke linkerd E benchmarks, you should find a whole bunch of Open Source Benchmark Frameworks and results.
00:12:59 [W] Talking about how expensive it is to run linkerd e and the answer is well, it's more expensive than not having a servicemeshcon.
00:13:26 [W] Awesome.
00:12:54 [W] That's linkerd. E2 - proxy.
00:12:57 [W] Here's a little snippet from the security audit.
00:13:00 [W] Of course. The full audit is in the repo itself a typically excellent code readability careful choice of implementation languages.
00:13:08 [W] Yeah.
00:13:09 [W] It was a good report.
00:13:10 [W] Okay.
00:13:12 [W] We actually have a newer version of these numbers.
00:13:17 [W] Unfortunately that newer version was not available in time for me to record this but if you search for convoke
00:13:24 [W] Linkerd e benchmarks. You should find a whole bunch of Open Source Benchmark Frameworks and results talking about how expensive it is to run linkerd e and the answer is well, it's more expensive than
00:16:29 [W] We're going to pick on sto a little bit and I'm happy to take questions.
00:16:34 [W] I'll be around during the Q&A period for this in my mind because this is such a common one.
00:16:39 [W] I want to adjust it up front.
00:16:41 [W] I think comes down to what do you need in a servicemeshcon?
00:16:59 [W] Sdo is extremely feature-rich and works in many many different environments under many many different situations linkerd linkerd.
00:17:11 [W] He's very focused on doing the bare minimum.
00:17:13 [W] So we are very focused on the kubernative use case and we're very focused on making it so that if you want the power of the servicemeshcon, you don't have to do any configuration at all.
00:17:25 [W] at least certainly not to get started and we'll do as much out of the box for you by default.
00:17:29 [W] Course that doesn't mean we're hiding things away from you were also very focused on visibility and introspection.
00:17:35 [W] So at every point, you know exactly what linkerd he's doing and you can understand the city-state of the mesh as well as how it's helping your applications.
00:17:45 [W] Okay, so lots more to be set on this obviously, but at this point I'm going to turn it over to my fellow linkerd e person to ruin puffle a potty who's going to tell you a little bit about what has been cooking and the linkerd E kitchen and what is
00:17:59 [W] coming soon.
00:18:00 [W] So take it away to roon.
00:18:04 [W] Thank you, William.
00:18:05 [W] Hello everyone.
00:18:06 [W] My name is Erin and I'm one of the maintenance of the linkerd E project in today's my part of the session.
00:18:10 [W] I'll try to cover the current road map of the project and also the current state of the linkerd E project as well and also the future remember the first we'll start with the 2.8 release which I which added support for multi cluster.
00:18:22 [W] This means that you can have applications across clusters talking to each other in a secure manner.
00:18:27 [W] This is possible by adding a new component called the multi cluster Gateway that acts like an entry point into your trust.
00:18:34 [W] And all the all the communication from other classes will flow through this has the following goals.
00:18:40 [W] So it expects a unified trust domain that is related across all cluster across clusters during during communication.
00:18:48 [W] There is no single point of failure, which means that even if a cluster goes down, it does not affect the service the multi cluster functionality, but for your application, you can use things like Graphics protect cetera to fail over onto other clusters etcetera.
00:19:01 [W] Applications are no other clusters.
00:19:02 [W] It also does not have a requirement on the networking primitive that the cluster users.
00:19:07 [W] So the so you can have these this feature in in an enormous like the private and Norman sweep ez-zor on the open internet.
00:19:14 [W] also Builds on the same unified in clustered communication model which means that all your metrics traffic splits Primitives, like graphics music cetera service profiles will work out of the box.
00:19:24 [W] Multi cluster functionality, but for your application you can use things like Graphics protect cetera to fail over onto other clusters Etc applications run other clusters.
00:19:16 [W] It also does not have a requirement on the networking primitive that the cluster users.
00:19:20 [W] So the so you can have these this feature in in an enormous like the private environments. We PCS or on the open internet.
00:19:27 [W] It also Builds on the same unified in clustered communication model which means that all your metrics traffic splits Primitives, like graphics music cetera service profiles will work out of the box.
00:19:37 [W] These next two point eight degrees also also has a ton of other improvements around Helm the installation VX cetera next. We'll talk about the current latest release the 2.9.
00:19:49 [W] Oh boy named if by the time you're watching this talk, the release would have already gone out. So feel free to try that out and give us feedback.
00:19:57 [W] If so, the flagship feature is TCP.
00:20:00 [W] I'm diligent load balancing, which means that not only or HTTP requests all your TCP connections will be empty list and load balanced out of the box without any extra configuration. The this has been one of the requested feature.
00:20:12 [W] So we also added support for armed 64 which means that you can run the air like the control been on the proxies on on
00:20:18 [W] I'm 64 devices like the Raspberry Pi etcetera of also added support for bring your own promises, which means I previously whenever you install even now whenever you install linkerd you have linkerd gets its own Prometheus, which is used to power the dashboard the CLX cetera
00:20:33 [W] under here, like the control been on the proxies on arms 64 devices like the Raspberry Pi etcetera of also added support for bring your own province, which means I previously whenever you install even now whenever you install linkerd you have linkerd ght tone Prometheus, which
00:20:48 [W] To use your own Prometheus that you already have in your environment. So that the control panels cetera can talk to your Prometheus to power the dashboard section. We also made it made of the existing linkerd Prometheus more configurable so that you can have things like remote right
00:21:03 [W] regulations on the lay on the linkerd E Prometheus
00:21:06 [W] We also added support for service to apology service to apologies is a relatively new feature in kubernative is that allows you to have no topology of a load balancing. So for example, if you if a client is connecting to do a service, it should probably talk to the
00:21:21 [W] The same node, or at least on the same availability zones so that the latencies or lower or rather than some other some other one.
00:21:24 [W] So if you have service toppled is configured with that information linkerd, I will take that information into account whenever it's taking a load balancing decision will Meto so as to have a latency available so that to have a less latency.
00:21:37 [W] So we also did a foundational change on how we store State and retrieve it during upgrades.
00:21:42 [W] So essentially previously as linkerd is being adopted more widely. It has been a problem to add more.
00:21:47 [W] Operations Etc specific to environment Etc.
00:21:50 [W] We may be so we we made it easy to add more configuration options without having to change that much change things at multiple places so that you can have more configurations on linkerd E 2.9 L is also has a ton of other improvements around multi cluster multi-threading in the proxy and
00:22:06 [W] Alternative foundational change on how we store State and retrieve it during upgrades.
00:22:08 [W] So essentially previously as linkerd is being adopted more widely.
00:22:12 [W] It has been a problem to add more configurations Etc specific to environment Etc.
00:22:16 [W] We may be so we we made it easy to add more configuration options without having to change that much change things at multiple places so that you can have more configurations on linkerd E 2.9 L is also has a ton of other improvements around multi cluster multi-threading in the proxy and
00:23:12 [W] Just the 2.9 release is a reserved very tightly packed release and I will highly recommend you to check out the release notes to understand the scale of this release next.
00:23:22 [W] We'll talk about the 2.10 and Beyond so
00:23:26 [W] so first obviously will have a will work on the server speaks first protocol which means that for applications like my SQL Etc if the server speaks first rather than the client it's hard for the proxy to to do protocol detection and doodoo mpls on top.
00:23:39 [W] So what they're planning to do is to have a very for the court to further user to configure things so that the proxy can configure that it's a server speaks was protocols and solar the proxy can act accordingly.
00:23:52 [W] We'll also be adding support for multi-class a TCP, which means that not only are
00:23:56 [W] To be connections can flow through the multi cluster Gator, but also all kinds of TCP connections that and it is and they are empty LS obviously with both of the more changes done.
00:24:07 [W] What we can do is demand we can mandate TLS by default in your cluster. So what it means that linkerd expects you to have some configuration to tell you that to to tell linkerd e that there is some kind of communication that you don't want
00:24:22 [W] So it means that by default all all your mission applications all the all if you if all the applicants in a cluster or measured it essentially means that you have TLS by default every weight, which is awesome for security and auditing purposes.
00:24:34 [W] Obviously, we will also be having an ink minimal control and install so so what we're trying to do is that even though the linkerd E components right now of can work independently.
00:24:44 [W] The installation package is a bit tightly packed to allow you to do that. So what we're trying to do is that to have to
00:24:51 [W] break up these components into modules that you can independently installed and incremental it's also for example first, you would start with the core control plane that consists of the proxy injector.
00:25:01 [W] The destinations of is the identity service and then you can incrementally install things like the dashboard on top.
00:25:07 [W] So this is makes the installation installation approach more simpler and also more flexible based on your environment Etc will also be doing authorization authorization obviously, so which means that you want to
00:25:21 [W] the video configured policies on which service can access which other service and which service should not access which other services essentially will be adding will be adding a new new new primitive around those lines to make it possible to configure Loi and deny rules based on that
00:25:37 [W] Learn also more flexible based on your environment Etc will also be doing authorization authorization obviously. So which means that you want to have a way to configured policies on which service can access which other service and which service should not
00:26:00 [W] We are also planning to have standardized apis and Adam Freeman.
00:26:03 [W] So so it is as so what is servicemeshcon loves to be built on top using it's a pi Sig is very important.
00:26:10 [W] So things like lacquer which does Canada deployments or the servicemeshcon interface Etc are built using the API.
00:26:18 [W] that is so servicemeshcon vitess. So to to add additional functionality like an agent that reacts to Golden Matrix and emits events and things like that. You want to have a standardized EPA on the on the
00:26:29 [W] on the servicemeshcon. We are trying to make the a be a more standardized so that it is easier for more developers to add to our to build agents and other things on top and we are also planning to have an add-on framework that makes it easy
00:26:44 [W] On the servicemeshcon. We are trying to make the a be a more standardized so that it is easier for more developers to add to our to build agents and other things on top and we are also planning to have an add-on framework that makes it easy
00:27:06 [W] Was that that makes it easier to have additional components installed together along the along with the along with the linkerd install like a kuruksetra?
00:27:15 [W] One of the we are we will obviously have a lot of other plants around webassembly plugins Etc as more and more of these use cases and feature requests pop-up will try to prioritize based on that and and have all these road maps are available as
00:27:31 [W] That and if you have if you are interested on any of them, you should definitely check them out or raise an issue. If you are interested in a specific use case and we can figure they're out.
00:27:40 [W] As it's a planned roadmap keep in mind that it can change. So next we'll talk about the getting involved side of things.
00:27:45 [W] So I'll tell my story first. So like a year ago.
00:27:48 [W] I was a cncf intern at Oregon linkerd on various bug fixes on the SMI project Etc.
00:27:53 [W] And then I have been kept contributing on did now I'm one of the Mandan of the project is awesome, I guess. So if you are interested in contributing to the project are more than help help help having you and help you and help you get started contributing to a provinces
00:28:08 [W] Eject is also make this so if you are interested in contributing to the project of more than help help help having you and help you and help you get started contributing to a provinces project not just implies that you have to write code.
00:28:17 [W] There are like a hundred different things are that you could do a project. For example, you can write a blog post on a specific problem that you that you that you face during the install and blog about it. So that other users can then take note.
00:28:30 [W] I'm sure a lot of users would fall into the same problem. We have a very active
00:28:34 [W] A community, we're not just the maintenance but also but also the users ask questions and all the answers and also answer unser's between themselves.
00:28:43 [W] all our development activity happens on GitHub by using issues and using issues under discussion feature.
00:28:50 [W] We also send a mailing lists Etc about the project updates Etc. We also have monthly Community calls. Where are we where we provide an update on? What's been what's been watching cooking in the project and also take
00:29:04 [W] Feedback questions. If you are interested, we are more than happy to help you get started. Thank you.
00:29:20 [W] Okay.
00:29:21 [W] Well, thanks everyone here. I am we actually have a lot of time for questions.
00:29:28 [W] This is me live William.
00:29:29 [W] You just saw recorded William from weeks and weeks ago.
00:29:32 [W] And then before I get started, I just wanted to point out that the slides you saw are actually also part of the open source. And so you can find them on linkerd E dot IO, so if you want to give a presentation about linkerd e just go to linkerd E dot IO find the slides and you can download
00:29:47 [W] them to your own devices
00:29:52 [W] Okay. So, let's see. The very first question. I'd like to answer is not a question.
00:29:57 [W] It's from Duane. So it's not really a question. But I love the hat. Well, thank you.
00:30:02 [W] You can actually get this hat yourself.
00:30:03 [W] It's very easy. All you have to do is install linkerd e in production and then once you do that, there is a form on the website you can go in and requests whack.
00:30:17 [W] You have to add yourself. Sorry if I had your self to adopters of MD and then you can fill out this form and
00:30:21 [W] Get passengers and things so that's how we bribe people to install linkerd e, so thanks for that that semi question going. So the next question is
00:30:36 [W] Says are there plans to adopt opentelemetry and the answer is yes.
00:30:40 [W] So right now linkerd Esports open senses open census is I think it's deprecated or it's on hold or something and then opentelemetry is a new thing.
00:30:49 [W] So, I think we're waiting for it to stabilize a little bit and then we'll just move everything over.
00:30:56 [W] I don't think it'll be a huge amount of work.
00:30:59 [W] But thank you for that question will seem yeah. The answer is yes, we're going to do that.
00:31:05 [W] And you know, if you don't find an issue about that already on on the GitHub, then feel free to just make an issue and you can get the status there or you can contribute.
00:31:16 [W] Okay.
00:31:17 [W] Next question is from Brian Casey who asks for multi cluster gateways. Is there a Max latency for long-haul use cases?
00:31:26 [W] I actually had to look this one up.
00:31:28 [W] The answer is no there's not really a Max latency that linkerd e in poses at least will you know you can set timeouts to whatever value you want.
00:31:37 [W] So hopefully it'll work for you. Although you know, if you have a 10 second latency, I think I don't know. I don't know your application might have
00:31:46 [W] Trouble itself, but you know the goal for us was to basically not impose any real requirements or assumptions about that connectivity between clusters other than kind of Gateway connectivity.
00:32:01 [W] status there where you can contribute
00:31:58 [W] Okay.
00:31:59 [W] Next question is from Brian Casey who asks for multi cluster gateways. Is there a Max latency for long-haul use cases?
00:32:08 [W] I actually had to look this one up.
00:32:09 [W] The answer is no there's not really a Max latency that linkerd e in poses at least will you know you can set timeouts to whatever value you want.
00:32:19 [W] So hopefully it'll work for you. Although you know, if you have a 10 second latency, I think I don't know. I don't know your application might have
00:32:28 [W] Trouble itself, but you know the goal for us was to basically not impose any real requirements or assumptions about that connectivity between clusters other than kind of Gateway connectivity.
00:33:51 [W] Hopefully that answers your question Brian.
00:33:53 [W] Thank you for that.
00:33:54 [W] Okay.
00:33:57 [W] Oh, gosh, we got a good set of questions.
00:33:59 [W] I'm going to do my best to get to get to all of them. So Nathan asks, is there any chance that the off policy or the off / policy layer in the future will be pluggable for example console eight tackles being used with linkerd or something like that
00:34:14 [W] For policy we were in the middle of figuring this out right now Nathan, so please jump into either the slack or you know into the corresponding GitHub issues.
00:34:24 [W] I think the answer is probably yes, like it would be to me. It feels out of scope to have linkerd e the project Define like its own policy framework,
00:34:39 [W] Place to enforce the policy right because it's in the position to do that.
00:34:42 [W] But so I believe that will be pluggable, but I'm I'm probably not the best person to ask.
00:34:51 [W] So yeah hop in to slack off into GitHub and thank you for that.
00:34:55 [W] Great question Nathan.
00:34:56 [W] Okay and Nick asks, what is the timeline looking like for the 2.10 release? Lots of features there that I am interested in.
00:35:04 [W] Okay, great my suspicions you have to take this with a huge grain of salt.
00:35:08 [W] Because of course it's an open source project is that we were targeting end of the year.
00:35:13 [W] I don't really think that's going to happen.
00:35:15 [W] I think probably January of next year January February so early early next year is more likely for that.
00:35:20 [W] But please don't hold me to that.
00:35:23 [W] Okay, Aaron asks, where can we go to get the benchmarks? You mentioned during the presentation?
00:35:30 [W] Okay.
00:35:31 [W] Well that was a bit of a gamble Erin I kind of was hoping that the most recent that a refreshed set of those benchmarks would be out.
00:35:38 [W] The time we were having this presentation, but they're not out. I think in the next week or two we should see them. So right now it's there, you know are the ones from last year the so if you search if you look at those, you can search for Kinfolk linkerd e benchmarks, you'll
00:35:53 [W] Of those benchmarks would be out by the time we were having this presentation, but they're not out. I think in the next week or two we should see them. So right now it's there, you know are the ones from last year the so if you search if you look at those, you can search for Kinfolk linkerd
00:36:12 [W] I envy you LK it's a company that does those benchmarks you can find that those graphs that I showed and we'd like I said, we are trying to refresh those but you know, they're not available just yet.
00:36:26 [W] So stay tuned and thank you for the great question.
00:36:30 [W] Okay, Joe asks, can you talk more about authorization for service to service requests?
00:36:38 [W] Yeah. So this is kind of related to that policy question above.
00:36:42 [W] Of I think there's two basic sets of requests or feature kind of requirement that we hear one is around kind of service level off. So what you can do with network policy today, although for a variety of reasons.
00:36:55 [W] It's not always possible to really accomplish this with network policies were things like, you know, the service a allowed to talk to service be right that would be an example of authorization or or even on a per route basis.
00:37:06 [W] You know, it's this service allowed to call this particular router method on one service be so right now linkerd he doesn't
00:37:12 [W] But we're set up to do it, especially with the 2.9 release.
00:37:18 [W] We now have em TLS for all TCP communication which means we have identity and both sides and we know what that service identity is the other kind of authorization that we hear a lot of requests for is around JWT off which is more kind of like
00:37:33 [W] Talk to service be right that would be an example of authorization or or even on a per route basis, you know, is this service allowed to call this particular router method on service be so right now linkerd he doesn't do that, but we're set up to do it
00:38:29 [W] Data, this client has you know or sorry that this request is associated with a client who has the capability of making this call.
00:38:39 [W] That one's a little more complicated and for that one.
00:38:41 [W] I'm also going to defer you to either the slack Channel or to GitHub.
00:38:45 [W] We've definitely talked a lot about it.
00:38:46 [W] I don't know exactly where we are on the design process for that.
00:38:51 [W] thank you Joe. That was authorization for service to service requests.
00:38:58 [W] Okay, gosh, I hope this is still entertaining for people a couple more questions, but we're going to have time so, you know, if anything is on your brain throw them right in this box here.
00:39:08 [W] Okay door and asks, how is linkerd e scalability of the control plane or data plane for extra large clusters, for example, 10,000 services and 30,000 pods - should be fine.
00:39:25 [W] That's a great question.
00:39:29 [W] I myself am not aware of anything that would limit linkerd e today, but I think mostly there's no design decision.
00:39:39 [W] I think that would affect that but I you know, I don't know that it's been tested at that scale 10,000 Services 30,000 pounds.
00:39:51 [W] I yeah, I don't know. So I think it would need to be tested and if there were issues, I'm sure they're fixable.
00:39:58 [W] Right. There's no kind of inherent scalability limitation.
00:40:01 [W] So it's probably more a question of like every really tested this I guess if I really trying to sell this project, I think yes, absolutely.
00:40:06 [W] It will work.
00:40:07 [W] But you know trying I'm trying to be honest. Okay bj at say William we are close to running in production.
00:40:14 [W] Oh, that's great.
00:40:15 [W] You can get a hat just working out the multi clustered domain requirement which clusters all need the same domain was wondering if you're planning on adding console service look up integration.
00:40:25 [W] Hmm.
00:40:30 [W] I don't think we are planning on adding that but that's certainly something that could be contributed.
00:40:37 [W] Just see if there's anything out there with anyone working on this today.
00:40:36 [W] And if not, then hop into the contributors Channel and slack which is where you know, you can go to get help on actually adding stuff to to linkerd e and there's a there's also an RFC process, which
00:40:51 [W] I have to go through depending on kind of the magnitude of the feature.
00:40:53 [W] So BJ if you're interested in getting all the fame and Glory associated with being a contributor to and cncf open source servicemeshcon.
00:41:15 [W] Okay, so let's take a look here.
00:41:17 [W] I think I've gotten through most of the questions unless I am failing at pagination here looks pretty good.
00:41:24 [W] Okay, we still have another few minutes.
00:41:26 [W] So if you want to ask anything, I will be available. We've got four minutes ask me anything hashtag am a there's oh there's one more from Kyle.
00:41:37 [W] Sorry Kyle.
00:41:38 [W] I didn't mean to skip you.
00:41:40 [W] Let me see. Where are you here?
00:41:44 [W] Why?
00:41:45 [W] Oh, yes.
00:41:46 [W] Okay.
00:41:46 [W] Here we go.
00:41:46 [W] I was feeling it pagination.
00:41:48 [W] I don't see a question from I'm sorry, Kyle.
00:41:52 [W] Let's see.
00:41:54 [W] I do see a question from a rat who says why are you comparing IBM sto? Is it one of many contributors to the project compared to linkerd e which is only one contributor here at that's the really confusing.
00:42:08 [W] Question, I don't really understand what that means linkerd.
00:42:11 [W] He has hundreds of contributors and it's all up there on GitHub.
00:42:16 [W] Hit that.
00:42:17 [W] Okay, Kyle asks, what's the link for deploying to production to get the Hat? Oh, okay.
00:42:22 [W] Yeah, so if you go onto linkerd e dot IO you'll see there's a button on there and says I use linkerd again. If you click on that, it'll take you to a form and like I said you have to add yourself to a doctor is not an MD.
00:42:35 [W] So that's our bribery mechanism. Does my Docker desktop on Windows count.
00:42:44 [W] Sorry Kyle that
00:42:46 [W] Does not count I want a real production deployment.
00:42:49 [W] It's got to be real the Hat. This hat is not something we just give away you have to run linkerd e
00:42:57 [W] Okay, and I see let's see.
00:42:59 [W] Oh, that's a good question from Karthik can linkerd e be deployed on Docker swarming. Does it only work on kubernative so great question card that it only works on kubernative.
00:43:10 [W] So there was a linkerd e 1 dot X and you can read you know in that in the kind of the beginning part of the presentation. I had a link to an article where I wrote some of the history but linkerd e 1 dot X actually supported many many different systems
00:43:25 [W] or actually but it did support amazos and console and a bunch of other things and as part of the move to 2 dot X, we lost a bunch of that and really just focusing on kubernative and there's a whole bunch of like complex reasons why primarily
00:43:31 [W] And things like that, it's much easier for us to build an extremely simple to operate servicemeshcon.
00:43:28 [W] You can focus on one particular deployment platform.
00:43:30 [W] sadly, the answer is 2 dot X is kubernative specific today, but thank you for that question.
00:43:40 [W] Okay, so does it work as a meshmark a one last question and then we'll wrap things up.
00:43:45 [W] So William asked some great named William. Does it work as a mesh 4K native?
00:43:51 [W] Yes, I believe the answer is yes, I in fact, I think if you search for linkerd e and K knative you will find a blog post that someone on the linkerd E team wrote.
00:44:00 [W] Um, so yeah should be fine and then that function I think it, you know, primarily responsible for T less than metrics and things like that.
00:44:07 [W] Okay.
00:44:08 [W] So thanks everyone.
00:44:09 [W] I really appreciate you coming here.
00:44:10 [W] Please go to linkerd E dot IO there is a ton of stuff that's out there that I haven't had a chance to talk about it all and we have a very welcoming friendly Community.
00:44:19 [W] I would love to see you and by watching this talk, you are all members of the community. So welcome to the linkerd E project and I hope to see you one day wearing one of these hats.
00:44:31 [W] Thanks, everyone.
