Panel: Introduction to the Container Orchestrated Device (COD) Working Group: OTNB-7040 - events@cncf.io - Wednesday, November 18, 2020 3:02 PM - 34 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hello everyone and welcome to this panel introduction to The Container orchestrated device group or ceoddi working group.
00:00:10 [W] My name is Reno kubectl.
00:00:13 [W] I'm a member of the IBM. I work on open source development and in a group that gets a chance to work all the latest greatest stuff.
00:00:23 [W] It's a lot of fun.
00:00:24 [W] particular it maintainer on containerd e o CI projects. I work with the Sig no team in kubenetes and maybe a bunch of other cncf project.
00:00:39 [W] Hello, I'm Alex. Hunter can have ski I work for Intel as Cloud software architect my main focus and areas where mostly involved is enablement of different accelerator devices and
00:00:54 [W] management like with complex problems
00:00:45 [W] Hi, I'm Renata Patel.
00:00:47 [W] I work for Red Hat.
00:00:48 [W] I've been working on containers for a long time been a maintainer of lip container run cocl runtime spec cryo and I participate in Sig node.
00:01:00 [W] Obscene everyone and we're rushing. Mohnani.
00:01:02 [W] I'm an engineer at Red Hat working in the container one time space and I'm a maintainer of cryo and participate in Sig note as well.
00:01:11 [W] So let's start this panel with a brief introduction to the con who container orchestrated device work with we are a small group of device vendors runtime
00:01:26 [W] Readers as well as communities Sig members this working group falls under the cncf runtime umbrella Sig runtime, eyebrow. Sorry, and this is because we interact with many projects
00:01:33 [W] Sorry, and this is because we interact with many projects such as kubernative Nomad containerd e cryo and other projects like Keda or in
00:01:40 [W] Other projects like Keda or in the HPC space Singularity or saris.
00:01:45 [W] The charter of this group really is to improve the support of devices in the color knative space and across it what that really means is that we're trying to enable new workloads.
00:01:59 [W] trying to smooth out the experience that you have as a user or as a cluster administrator, and we're also discussing.
00:02:09 [W] Covering and trying new ideas such as defining the bout the security boundaries for devices.
00:02:17 [W] In what that really means?
00:02:19 [W] What does it really mean to try and enable new workloads?
00:02:23 [W] That's a question and then I'm going to be asking and looking very intensely at Alexander from endo.
00:02:31 [W] Frank's are no such introduction of working group and indeed the usage of devices and past five years or so is growing in the cloud and like what iot of workloads iot lies on devices
00:02:46 [W] Don't it's not uploading acceleration encryption compression.
00:02:50 [W] whatever things what can offload why CPUs and devices, which actually we are talking about just to name a few like we have Nvidia gpus one of the most commonly used
00:03:05 [W] And from our from Intel site, we have fpga quick assist also gpus and some other devices when from different vendors.
00:03:01 [W] We have Smart Knicks and obviously all of those vendors who have a devices once to enable them in the cloud and the way how it's enabled its evolving if previously it was just
00:03:16 [W] I'm deaf. My device nowadays. We users are expecting to have it in more complex setup in example, a kubernative distributed orchestrated workloads. And by the way coders to Renault and the video who drove
00:03:29 [W] One of the ways plugins and work overnight has but actually simplify it a lot usage of Nvidia gpus in device more learning.
00:03:35 [W] Sorry, if learning model training the main thing actually which it helped it helped to change from mindset of a cloud users.
00:03:47 [W] What device is made is not something rare. It's something it's a commodity what way can be utilizing inside wave workloads.
00:03:54 [W] Loodse and change convert in the mind actually brought a lot new subset of problems both from use cases perspective and from a user experience perspective.
00:04:10 [W] Mostly user wanted I wanted device nowadays.
00:04:11 [W] We are talking about a lot more complex scenarios like one scenario is we have a VMware based runtimes and we want to use devices where we have devices which have different properties.
00:04:23 [W] So for example user say I want a PGA this particular bitstream load or we have connected devices with less Martinique say is I want to be connected to specific Network and RDMA pipeline.
00:04:37 [W] When we have even more complex scenario and multiple devices using node is connected as a pipeline like fpga unique special Isaacs and so on and then the worst case scenario something what in media trying now to
00:04:52 [W] Multi-node deep learning so why you have a device is connected between the notes and you have a problem with what device become a resource not as a single node, but a cluster source and
00:05:02 [W] Is worth in the workloads, they end up what way existing all extension points is not enough.
00:05:01 [W] We need to do a lot more we how we describe in devices for way how we prepare and devices will be how to prepare and workloads.
00:05:24 [W] He needs to be improved the overall user experience needs to be improved to enable all of this.
00:05:31 [W] That's some pretty cool you skills is so special devices are now kannada D. Are they special devices now?
00:05:37 [W] What do you think your veggie I've heard about this clydie called CDI the containerd device interface. Could you talk to us about it?
00:05:46 [W] How does it helps of these different use case that likes from Intel just talked about?
00:05:52 [W] Yes, that's a very good question.
00:05:54 [W] So the containerd device interface or CDI for short describes a mechanism for containerd 1 times to create containers which are able to interact with third-party devices So currently there is no standard for device support in one times an orchestrator
00:06:09 [W] Containerd device interface.
00:06:10 [W] Could you talk to us about it?
00:06:12 [W] How does it helps of these different use cases that likes from Intel just talked about?
00:06:17 [W] Yeah.
00:06:19 [W] that's a very good question.
00:06:21 [W] So the containerd device interface or CDI for short describes a mechanism for containerd 1 times to create containers which are able to interact with third-party devices So currently there is no standard for device support in one times an orchestrator engine,
00:06:52 [W] For example, kubernative and Nomad what type of concept of device plugins but they have very different Frameworks with these device plug in soccer has an entry plug-in mechanism while for admin has a concept of Hope and this holds true for other
00:07:07 [W] I'm an office Shredder engines as well this lack of standard results in vendors having to write and maintain multiple plugins for the different one time.
00:07:17 [W] So with the CDI the plan here is to have a standard way of support and Kurt for your devices so that the user experience is consistent regardless of which one time or orchestrator used portability between 1 x will be easier and there won't be
00:07:32 [W] I can be your hat for the different runtime which in turn means that mutant ability will not be a nightmare or at least much less of a nightmare.
00:07:42 [W] So in the next it is quite straight forward to expose a device node into container for simple device.
00:07:47 [W] All you need to do is pass the flag and the device Labs your runtime.
00:07:51 [W] However, complex devices like GPU is an fpga is require much more involved operation as Alexander mentioned earlier, these operations can range from things as simple as compatibility check in my container run on this device
00:08:06 [W] a big operation like reconfiguring an entire fpga or memory management and gpus
00:08:10 [W] Now the Syria is only concerned with providing containers with the ability to be aware of devices fast. Like Resource Management does not part of the scope of the CDI this narrow scope greatly simplifies implementation of the
00:08:25 [W] But flexibility for runtimes and orchestrator engines the senior follows the model of the container networking interface. A Json file is return written to a well-defined path on the machine. The Json file contains
00:08:35 [W] Mission on device-specific as well as operations that we container once I need to support and this information is used to transform the OCS pack accordingly which in turn results in advance having a seamless experience while setting up
00:08:48 [W] So basically the container orchestrated devices were thin Kudo is aiming to improve the supported devices and the cloud knative space and TDI is our first effort in the field.
00:08:57 [W] It's a really cool introduction to CDI.
00:09:01 [W] Thank you very much.
00:09:02 [W] You're very she you just said that currently the Space is really fragmented and that different orchestrators have different mechanism. Rennell you are
00:09:15 [W] A contributor to the oci which is a standard spec. Could you tell us a bit more how you thought or how you think this is doable or this?
00:09:27 [W] This is this use case is a dress today.
00:09:29 [W] Sure.
00:09:30 [W] So if you think about the oci runtime spec the way it works is you write a config dot Json that describes how a container is created and run so think of the properties of a container
00:09:45 [W] Such as its root file system like it could be based on Ubuntu what you see inside a container all the files that the root filesystem the process that you run.
00:09:53 [W] It could be like a bash shell the namespaces from Lenox that are used to define the container and the security aspects of it such as selinux capabilities and so on so when
00:10:09 [W] Standard spec. Could you tell us a bit more how you thought or how you think this is doable or this?
00:10:17 [W] This is this use case is a dress today.
00:10:19 [W] Sure.
00:10:20 [W] So if you think about the oci runtime spec the way it works is you write a config dot Json that describes how a container is created and run so think of the properties of a container
00:12:15 [W] The OCR runtime spec was created networking was one aspect that was considered as out of scope. And the reason being that there are tons of ways to set up networking for a container and different vendors would
00:12:30 [W] Tons of ways to set up networking for a container and different vendors would have different solutions at layer 2 or layer 3 and the runtime spectin to want to get in the way of trying to Define every possible way to set up networking.
00:12:45 [W] The setup networking.
00:12:47 [W] So the idea was to introduce hooks, which can then be used to join the network name space of a container and then set up the networking as you see fit.
00:12:57 [W] So that was one use case and another use case I can think of is enabling system B. So for hook sees that someone is trying to start the system D process in a container. It can set up the right mounts the right cgroup s'
00:13:12 [W] So systemd can start up seamlessly without any additional set of by the user and the final most interesting use case is enabling gpus.
00:13:23 [W] So gpus have a lot of setup that are that is required Beyond just adding the device node in the container like setting up additional Mounds running Keda config and so on so initially this started
00:13:38 [W] But with a custom hook that performed all these steps like but writing this hooks is not easy.
00:13:41 [W] You have to know the knowledge. You have to know the internals of how containers run how runs he works with Mount namespaces and so on and then you to join all these names faces and perform these operations.
00:13:54 [W] So it's a very imperative low-level bug prone approach if I would say so and there are also some
00:14:03 [W] urkki risk. So if you think about it run C or any container runtime is better suited to perform these operations.
00:14:11 [W] So writing all these hooks you can see a pattern emerge that most of what these hooks are doing can be done by run C. So that's why the idea of CDI is
00:14:26 [W] Knative so CDI Allah allows you to declare what additional changes you want to make to your containerd. Like you want to add a mount. You want to run a hook you want to do some additional configuration.
00:14:36 [W] So instead of here hook doing all these operations CDI is allowing you to make changes to the spec file so runs he can perform those operations for you. So that's how CDI helps and simplifies the
00:14:51 [W] Cisco
00:14:53 [W] Thank you for this example and just explanation of what happens in the low-level talking about low level.
00:15:03 [W] I know that Mike is a contributed to containerd e and I've been following a bit that space and I heard about this new ID that's called an r i could you talk to me about a nor I is it the same thing as CDI? Is it something
00:15:18 [W] What do you think?
00:15:03 [W] You know, I think it's I think it is somewhat different but I think there's a huge opportunity right now to to integrate the efforts between between, you know CDI and the NRI effort
00:15:19 [W] Les work with the Sig no team with you know with kubernetes at coming up with a you know additional integration.
00:15:20 [W] We haven't mentioned much about the containerd runtime interface, but the cri-o
00:15:41 [W] That are that are on these nodes themselves directly in some cases.
00:15:45 [W] They needed to monitor monitor their health with probes and and they went around containerd runtime and that became a problem in some areas while we've all agreed to you seen I for networking integration at the content of runtime level for the containerd runtime.
00:16:00 [W] Implementations and we think that's been a good model. It hasn't been the way we don't all the other resources.
00:16:06 [W] I think the the issue and all is that you know, some teams see see this from a pod spec level or a container specification level and other team see it for more from a low-level Hardware implementation level on the
00:16:21 [W] Teen access to those devices I can use outside of a container inside the container. Right and we're now certainly had a really good way to solve that problem with the hooks is very low level
00:16:28 [W] With me, you know who created The Run see originally came up with this idea after looking at all this and answer asking a lot of questions.
00:16:33 [W] It came up with an idea to do a new node resource interface that would would provide for the capability to add plugins that container runtimes would implement or be able to to be able to run that would actually
00:16:48 [W] Looks in such a way that the containerd runtime knows that they're happening and hopefully with caps that will do for Sig node.
00:16:55 [W] Kubernative will also know what's going on and be able to manage those resources for my higher level perspective, you know by talking to the plugins through cri-o.
00:17:16 [W] Why you'll see you'll see a brand new repository that Michael created a bunch of code some samples and we're looking for ideas.
00:17:24 [W] It doesn't support pods yet, but that, you know, another PR will push that in so that you can you can actually create plugins to manage the resources for your pods and and containers using the hooks underneath the covers that that renowned team put together
00:17:39 [W] And hopefully will be implemented in the other runtimes yet.
00:17:40 [W] We'll have to work at the runtime team still like like Keda containers to make sure that when we at the shim layer where we host these instances, you know for a VMS or of containers that we that we got the ability to
00:17:55 [W] Instances, you know for a VMS or containers that we that we got the ability to manage. These hooks make to manage these access to these resources in the containers.
00:17:57 [W] So when the container writer just wants to use it.
00:17:59 [W] It's just there and it's easy to use get a better a better user, you know, better user feel when they create their pods packs and things just work.
00:18:09 [W] So what I'm hearing from you is that there's a lot of work, but it's exciting.
00:18:15 [W] All right.
00:18:16 [W] Let me go back to let me go back to the roadmap.
00:18:21 [W] I think it's really important that we talk about this group's roadmap to finish the presentation. It's
00:18:29 [W] So because we know intimately the problems we've decided to tackle it through late approach right now.
00:18:40 [W] We're solving this core problem, which is how do we expose a device to a container and the solution that we've come up for that is CDI and as Bruno has mentioned it's a very declarative approach
00:18:55 [W] Thing that we are really excited to show as we continue through this process of solving these problems The Next Step here is the node level.
00:19:08 [W] How do we select which device needs to be assigned to which container and the problem that we're trying to solve here really is when you have workloads are very sensitive to Performance when you have workloads that have multiple devices talking together.
00:19:23 [W] And the problem that we're trying to solve here really is when you have workloads are very sensitive to Performance when you have workloads that have multiple devices talking together.
00:19:28 [W] You want to re very conscious about what CPU what memory what Nick would GPU what if BGA? What is your selecting if you have a CPU that is very far away from your neck or
00:19:43 [W] You're selecting if you have a CPU that is very far away from your neck or your Nick that is very far away from your device. You might destroy the performance to the point that it's might not be even worth talking to that, Nick
00:19:58 [W] Been worth talking to that Nick and so selecting which device needs to be assigned.
00:20:06 [W] It is a very difficult problem The Next Step here is when you start looking at it from a cluster level when you have workloads.
00:20:15 [W] they need to run on multiple nodes and communicate together or when you have devices that are over the fabric. Typically you want to have these devices talk to each other. The better talking to each other would be
00:20:28 [W] Very close for example on the same Rank and so the problems that we're trying to solve here. They require the ability to figure out where the right knobs to expose to the users where the right plugins
00:20:43 [W] And plug insistence and they're really exciting problems. But also very challenging and so there's still a lot of space to be discovered here.
00:20:53 [W] And this is the conclusion of this panel is that we are still very new group and there are lots of really exciting and challenging ideas.
00:21:03 [W] We'd like people to contribute and help us figure out where some of the solutions that could be done in the area. We would like feedback some of these
00:21:12 [W] IDs are going to interact very very strongly with other ideas out there and how do they intersect?
00:21:21 [W] So if you think that CDI might help you we'd be more than happy to have feedback from you. If you think that CDI might be something that that that that you could
00:21:36 [W] You could use if you think that ci/cd thinking or some of these ideas that were talking about you want to be able you want to integrate?
00:21:40 [W] Let us know we'd be very happy to hear about your use case. And the way that you could let us know is go to the Cod working group meetings.
00:21:50 [W] They happen every other week on Sig runtime zoom, and we're really waiting to hear from to hear from you. And with that said I'm
00:22:02 [W] I'm going to open the floor to questions from the audience.
00:22:17 [W] I would run and this is you know, I think we are going to start taking questions.
00:22:24 [W] I'm going to maybe start with the first one, which is this first question from Kevin Fox who asks are we making an exit oven like extension mechanism for cri-o?
00:22:45 [W] I can try to answer a wet one.
00:22:47 [W] So practically yes, it's extension but not really to share a what we are targeting for is actually a bit lower layer.
00:22:58 [W] To have consistent and easy user experience.
00:22:53 [W] Not only for kubermatic S.
00:22:54 [W] We also want to have the ability for user to use but bodman command line interface with Docker command line interface and double some areas the kubernative.
00:23:11 [W] All right.
00:23:12 [W] Thank you very much for answering that question. If you need any thought feel free to ask questions in the chat. Another question that was asked is where the means happening.
00:23:24 [W] We are using the Sig runtime Zoo.
00:23:26 [W] These meetings are separate.
00:23:30 [W] They had been every other Tuesday and you can follow and typically you'll find the meaning and the agenda on the Sig runtime distribution.
00:23:40 [W] Or mailing list.
00:23:43 [W] I based it a link to the meeting as an answer so looks when I just sat at easily.
00:23:50 [W] We do have some pervert questions. If no questions are if we don't have any other questions from the audience, maybe I can probably start with Mike
00:24:05 [W] You can find and typically you'll find the meaning and the agenda on the Sig runtime distribution or mailing list based on a link to the meeting as an answer.
00:24:05 [W] so looks when I just had it easily.
00:24:13 [W] We do have some prepared questions. If no questions are if we don't have any other questions from the audience, maybe I can probably start with Mike.
00:24:25 [W] We talked about an RA in this presentation.
00:24:28 [W] Can I start using it today?
00:24:30 [W] If so, how how do I start working with an alright?
00:24:40 [W] What we've got a project underway on containerd E where you can go ahead and sign up and and pull it down.
00:24:48 [W] It's already built into containerd e in master so you can actually, you know use it today.
00:24:55 [W] even a couple of samples but it is it is very new and we need we need help make to move it along for example. Nobody had talked about.
00:25:06 [W] Using Enterprise and extension mechanism for you know for adding more features to cri-o.
00:25:40 [W] Thank you very much for your answer.
00:25:44 [W] Can you tell us a bit how how one could contribute to the CIF herbs or the container or constrained device group effort?
00:25:55 [W] Yeah, sure.
00:25:56 [W] So as we mentioned earlier, we have meetings every other Tuesday using the Sig runtime Zoom.
00:26:03 [W] So definitely join those there's a lot of planning that goes around in that just discussing what the way forward is.
00:26:10 [W] We also have the tekton orchestra devices GitHub repo over there. We have a CD are equal under that so you can always go there take a look at the issues.
00:26:22 [W] We have created a simple request open right now.
00:26:25 [W] And the destroying the meetings and be part of the discussion, I think also for Noah's doing some proof of concept with broad man for that.
00:26:33 [W] So there's a lot of trial and error going on right now here I would like to add that there is work to be done in integrating and enabling CDI on the container and times like besides Padma and we have
00:26:48 [W] Cryo, and then there is also device vendors coming in trying to use CDI helping us refine it or make fixes to it as needed. So that will be helpful. If you are a device vendor trying to use this new easier way.
00:27:07 [W] And it's super interesting.
00:27:12 [W] Rodney asks any pointer to this code prototypes.
00:27:16 [W] Feel free to join the card working group meetings and ask these questions there but more specifically in the meeting notes you will find links to
00:27:31 [W] comment prototype
00:27:24 [W] and there are some discussions going on on the NRI issues around how this could get integrated in containerd e
00:27:38 [W] Maybe let me ask Alex about multi-node device setups.
00:27:43 [W] Could you tell me more or could you tell everyone hear more about consuming multi-node devices and how this looks like for example a kubenetes level
00:27:59 [W] Obviously we don't have solution right now what I different prototypes by different companies implemented to try to prototype how it can be used but in reality,
00:28:09 [W] What's going to happen in Industry quite soon is what we will see with our eyes of devices which is available over fabric wouldn't be like faster than that, or maybe some other
00:28:19 [W] All connections. So when when we are having this kind of setup example like this machine learning settings, so you will be transferring a lot of data between were components of
00:28:32 [W] voices and now you have a problem which require not only just allocating the device but also trying to place with multiple workloads like multiple what multiple containers on the machines
00:28:45 [W] Particular devices are connected.
00:28:43 [W] So like obviously you can try to work or work around what with not only believing scheduling using was small with labels, but it's well, I'll say crunches to some extent.
00:28:58 [W] Labels, but it's well, I would say crunches to some extent like workarounds instead of Ideal solution.
00:29:08 [W] So once we will be able to solve low level issues how we expose in such a complex devices. I think few components which needs to be improved with another project. So they don't need a scheduler
00:29:23 [W] The lower extension so it changes to one normal scheduler.
00:29:26 [W] We don't need to think about how this cluster level resources will be allocated.
00:29:32 [W] I don't know what the hell's it's Uncharted Territory for a moment.
00:29:42 [W] What you're saying is feel free to discuss these topics in the car working group enjoyed and continued.
00:29:50 [W] We will be happy to share discuss and collaborate on this new exciting ideas.
00:29:58 [W] So then is it turned out in and there's a question from Kevin regarding see a CSI image image driver and how it intersects with this this effort.
00:30:13 [W] So I think maybe I see both of these are separate like that idea is worth pursuing any ways to make it more first class and it could probably be used to make
00:30:26 [W] make like driver payloads be available in some cases, but I don't see CDI is targeted for that particular use case directly.
00:30:40 [W] Maybe I see both of these are separate like that idea is worth pursuing any ways to make it more first class and it could probably be used to make like
00:31:44 [W] Um in to add to what Morneau answered feel free to come and join we'd be happy to understand a bit more they use cases and see if there's anything we can help.
00:32:02 [W] I can probably ask one last question.
00:32:09 [W] I think maybe how about can can one of you or maybe Alex or more now, or can we can you can we talk about sure devices? Is that something
00:32:27 [W] I think baby.
00:32:28 [W] How about can one of you or maybe Alex or now or can we can you can we talk about shared devices? Is that something that?
00:32:56 [W] It is one of the most of it is is a very important.
00:33:00 [W] I mean, this is something that is a very important problem for a lot of people because it was better utilization of devices.
00:33:07 [W] and hence getting a better value for the money that you invested in these devices.
00:33:15 [W] there a plan for developing that support and different runtimes and different orchestrators?
00:33:26 [W] I'll probably I can speak about what so indeed were short of the y-axis is a great opportunity for my get more performance out of your money invested and Hardware well.
00:33:41 [W] Biggest problem this kind of shared devices as what we colonel. In fact, the kernel driver system is not always ready for sharing and limiting Above Water Resources.
00:33:54 [W] So, for example, we can think about what video memory for gpus or we can think about what timing for gpus so all of those controls not necessarily available through cgroup for something.
00:34:06 [W] It's something what community not only from
00:34:11 [W] cloud native side, but like what whole stack needs to solve in near future.
00:34:19 [W] Thank you very much Alex with this last question.
00:34:22 [W] The session is over.
00:34:24 [W] Feel free to bring new questions to the runtime cncf Channel and thank you very much for attending.
