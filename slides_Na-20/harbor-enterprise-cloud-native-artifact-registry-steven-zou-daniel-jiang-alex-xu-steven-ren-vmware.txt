Harbor- Enterprise Cloud Native Artifact Registry: KZAW-8692 - events@cncf.io - Wednesday, November 18, 2020 3:52 PM - 48 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hi everyone.
00:00:01 [W] I'm Alex.
00:00:02 [W] I'm very happy to be here at Kuma con North America to talk to everyone about the harbor project.
00:00:23 [W] Hi everyone.
00:00:25 [W] I'm Alex.
00:00:25 [W] I'm very happy to be here at could become North America to talk to everyone about the harbor projects.
00:00:32 [W] It's a shame that this is still a virtual conference and we can come in and share this in person. But I hope everyone is doing really well and thank you for tuning in.
00:00:41 [W] So today my co-presenter and I will talk a little bit about the harbor project.
00:00:46 [W] This is a graduate project in cncf and if this is your first time attending harm zettabytes
00:00:53 [W] Is think of it as a registry a place to store and manage your container images and other Cloud native artifacts.
00:01:01 [W] possibly.
00:01:02 [W] You're using Helm charts during a singularity files or it's something something else. But for the purpose of this session, we're going to be focusing mostly on the latest and greatest of the harbor project. So focusing on the latest version 2.1 release as well as
00:01:18 [W] On the latest and greatest of the harbor project so cozy on the latest version 2.1 release as well as some of the things we're working on.
00:01:26 [W] Is it upcoming 2.2? If you've never even a familiar with blood and image registry does and never been exposed to the basic set of capabilities that Harbor provides, please check out our website and check out.
00:01:41 [W] That previous kubeacademy swear. We've always had an introductory session that you know, sort of starts with what is an image registry what to do. What do you needed so that can be really helpful quick introduction.
00:01:55 [W] I'll know. I'm Alex shoe. I'm a product manager in the cloud native team at VMware leading the harbor effort. So responsible for trying to understand the requirements around the container registry for responsibly driving the world map collecting
00:02:10 [W] From you guys and making sure that we're building something that people will actually use and why actually want to recommend to their friends.
00:02:14 [W] It's an and today with me is my co-presenter Daniel John.
00:02:21 [W] Hey, Dan, you guys this is hey guys.
00:02:23 [W] this is Daniel.
00:02:25 [W] Yeah, I will present with addicts for you today.
00:02:28 [W] I will show you a few cool demos regarding the latest feature video where he and work into that one.
00:02:34 [W] I'm working for VMware as a staff engineer and maintainer of Harbor product.
00:02:40 [W] Glad to meet you.
00:02:41 [W] Thanks, Daniel.
00:02:45 [W] We've also listed to her colleagues to help us with this presentation.
00:02:51 [W] So shout out to Steven and Steven so as well.
00:02:56 [W] So, you know we start with intro slide and what is Harper.
00:03:00 [W] Well Harbor is a trusted Cloud native registry that can store sign and scan content.
00:03:06 [W] So it's basically a place to host a manager artifacts. And you know, when we started this project back in 2014 building an on-prem industry leveraging talking distribution, we came across some issues right when we were using
00:03:21 [W] And Stephen so as well.
00:03:19 [W] So, you know we start with interested in what is Harbor Harbor is a trusted Cloud native registry that can store sign and scan content.
00:03:28 [W] So it's basically a place to host a manager artifacts. And you know, when we started this project back in 2014 building an on-prem registry leveraging talking distribution, we came across some issues right when we were using
00:04:03 [W] Other public Registries, so we're over time.
00:04:08 [W] We you know address those issues and also added more services and features related to life cycle management security features, like scanning and signing images and recently we've been focusing on image distribution through TTP
00:04:23 [W] And proxy cash and now we're focusing on high availability delivering High ability highly available Harbor cluster through our operator.
00:04:33 [W] It's our mission is to be the best cloudevents tree for kubermatic.
00:04:37 [W] We started with support for Docker images.
00:04:41 [W] We expanded the helm charts and with Harbor 2.0.
00:04:45 [W] We can all support any rule see I can paddle artifacts.
00:04:50 [W] So let's start by looking at the community, which is thriving doing really well.
00:04:55 [W] So we have more than 13k GitHub Stars.
00:04:59 [W] We have 200 plus committers 50-plus Computing companies more than 4,000 Forks.
00:05:05 [W] We have 14 maintainers across five different companies.
00:05:09 [W] Across three different continents in North America and Europe in Asia.
00:05:13 [W] We've also seen a lot of diversity in our contributors as well in terms of backgrounds and skill sets from developers to develop Engineers to system admins and basically everyone everyone in their
00:05:28 [W] Needs around a registry to manage their artifacts.
00:05:33 [W] So we're extremely happy about this and and you know, we want to thank you guys for all the work you've done and thanks again for tuning.
00:05:46 [W] And so I want to just quickly jump into this and start with some of the things that we've been working on for the 2.0 release. The first one I want to talk about is called proxy cash, which is the ability for Harvard to act as a pull-through cash for another remote
00:06:01 [W] And you know, that's usually we call that the Target or the remote registry or the upstream and this is basically situations where you have a registry that you're trying to hit but you have either limited connectivity or no connectivity.
00:06:05 [W] To that Target and this could be because of compliance or it because of security issues or limited Equus options.
00:06:09 [W] so Docker Hub is a really great example of a client register of a Target registry. They're trying to hit right Docker Hub is a registry where Docker clients.
00:06:23 [W] From all over the world are trying to pull images from but if you're pulling too fast or you're pulling too frequently, then you can trigger the dot the docker Hub read limiter which can throttle your connection or even get you IP banned.
00:06:36 [W] So Harbor has a pasta cash is meant to address this very problem. In this case.
00:06:41 [W] It means that Harbor will serve as an intermediary to pull the images and cash them locally for you and then serve it to you to serve it to the docker cons. So it's much faster and
00:06:53 [W] It minimizes going over the network unnecessarily and prevents you from getting IP banned.
00:07:01 [W] So the way to to utilize this feature is basically when you're as you would when you're creating a harbor project, if you're familiar familiar with that workflow, there's an added option to enable it as a proxy project
00:07:17 [W] Then put in the side the Target registry and point.
00:07:18 [W] That's that's the point of your proxy for and so when you want to talk or pull from that remote registry, you will talk a pull from the proxy project instead and every time you do a pool it'll kick off a request to Harbor which will kick off
00:07:33 [W] That Upstream registry and and do a comparison to see if the image in its cache is indeed the most up-to-date copy.
00:07:25 [W] If it is it'll just serve the cached copy and if it isn't it will be pull recache it and then serve it to to the dark lines.
00:07:34 [W] you will have to modify your dr. Pol command and your pain manifest to hit the proxy project instead.
00:07:46 [W] So the second project or the second feature I want to highlight is called non-blocking GC.
00:07:50 [W] It's called non-blocking because prior to 2011 carbs collection will put the registry in read-only mode. So you can still interact with your existing artifacts and harbor you can still use the apis. You can still use the web console.
00:08:06 [W] Run certain policies you can still pull the images, but you can't push images and you can't delete them essentially for the entire duration of that GC execution.
00:08:11 [W] And so with the 2.1 non-blocking garbage collection users can push images to component is to control the images from Harbor while GC is running so it's completely runs completely silent in the background with no impact to use
00:08:26 [W] Have to worry about you know data corruption anything like that did a corruption is, you know, it was a potential concern for us because of the way the images are laid out and stored in distribution
00:08:33 [W] That the way the images are laid out and stored in distribution.
00:08:32 [W] They're essentially this is owing to the cross reference for nature of the TOC distribution with image layers are stored in the most efficient way possible with no redundancy there essentially to do across all the projects in a single Harbor
00:08:48 [W] So it's really great from a storage perspective. But you know, it can be tricky from from whenever you're doing something destructive like running garbage collection or you're deleting images and the way we were finally able to achieve this was we're essentially snapshotting
00:09:03 [W] there's that are marked to be deleted and then sort of continuously tracking and resolving these and against any incoming image blobs as part of a push request while GC is running so it's
00:09:18 [W] An important feature from an operational standpoint.
00:09:18 [W] It's very highly requested by large Enterprise users that have anywhere from hundreds of gigabytes to we've seen tens of terabytes of the images stored on each Harbor innocence and and because you know
00:09:33 [W] I mean depending on how often you run it if it's placed in read-only mode for an extended amount of time.
00:09:36 [W] And on top of that. There's no way to tell how long that job will run for or how much disk space Security will be the allocated from each execution, you know, that can be problematic and can be quite stressful.
00:09:52 [W] If you're in the software delivery business sort of software supply chain business where all the images are landing in your Harbor innocence and Year to one responsible for Distributing these to your customers.
00:09:57 [W] And so that's why we've added the ability to perform a dry run which will give you an estimation of the amount of disk space that would be freed up and so by making it non-blocking not only is it, you know, not incurring a penalty
00:10:12 [W] Use our operations not only is it running in a faster and more efficient manner but you know that the time it takes to run GC is no longer as much of a factor.
00:10:19 [W] It's no longer as debilitating to your business. If it goes over if it goes grunts River for quite some time, right?
00:10:29 [W] You're you're taking the pressure off the Garbage Collection aspect of maintaining a registry.
00:10:36 [W] So before I move on to two point two, Daniel will do a demo of the proxy cash as well as the online garbage the non-blocking garbage collection.
00:10:46 [W] let me stop sharing.
00:10:51 [W] Let me make sure that's still recording.
00:10:56 [W] Okay.
00:10:56 [W] Yeah, it is still recording.
00:10:58 [W] Yeah, so let me get started.
00:11:00 [W] Hi guys. So the first time I'm going to show you is proxy cash. I need to use the recording them all due to the instability of my network.
00:11:11 [W] Let's move on. So in the proxy cash to implemented we reuse the code of reputation. So the user experience also has some ovhcloud.
00:11:24 [W] Kay's I just created a Docker Hub and fun with my personal account.
00:11:28 [W] And I can create a new project note that in this dialogue. There is a new Switch a proxy cash.
00:11:40 [W] I can switch it all and select this in mind. I just created. Yeah after that. This will be the proxy cash project process images from Docker hub.
00:11:54 [W] Now that this is an empty product no images.
00:12:00 [W] And if I issue a talker pull command against this proxy cash product.
00:12:11 [W] Here, I want to poo go Harbor / Harbor coordinators from Docker Hub.
00:12:16 [W] VMI. Proxy cat for death.
00:12:18 [W] I just append this relative URI to the URL of my project of the harbor instance like this.
00:12:29 [W] And if I start pulling
00:12:36 [W] You can't see the images is serving directly via others proxy cash from Dover hub.
00:12:44 [W] The hood there in the background. There is no routine to write the content of the c major to Harbors storage.
00:12:51 [W] And because it's asynchronous you need to wait a couple of seconds you refresh and you can see that there is a repository Harbor core in the image.
00:13:03 [W] Note that once this image is stored in Harbor storage.
00:13:09 [W] It is the same as the images you pushed to Harbor. So it has all the information and you can do all the stuff to this images such as scanning or adding tabs removing tax
00:13:24 [W] Mass the images you pushed to Harbor so it has all the information and you can do all the stuff to this image such as scanning or adding tabs removing tax here. I simulate
00:13:36 [W] I'll tear drop Docker Hub by a messing up my DNS so that my Harbor instance cannot access this Docker Hub, and you can see the test connection. The ping doesn't work now,
00:13:52 [W] If I remove this image locally and Pull It Again from my doctor cry.
00:14:03 [W] Harbor will do the best effort to sync with the Target registry. But in this case it is not accessible.
00:14:11 [W] So Harbor will serve whatever is available locally.
00:14:16 [W] So in this case, you can still get this image that is cached in Harbor we can see there is really helpful for you to alleviate the problem caused by the rate limiting in the docker hub.
00:14:31 [W] Also worth mentioning that this proxy cash project has all the capabilities.
00:14:39 [W] Also worth mentioning that this proxy cash project has all the capabilities.
00:14:37 [W] For example, you can use called a policy to control how much images can be proxied and you can also set up this
00:14:55 [W] Attention policy to remove this style staled image cache so that you can you know serve the store the new uh, prophesied images.
00:14:59 [W] So that's the demo for the proxy cash.
00:15:04 [W] Next is a non-blocking GC non-blocking garbage collection devil.
00:15:11 [W] So as Alex mentioned the in when we implement this feature instead of relying on the dock or distributions code. We use this data in Harbor
00:15:27 [W] Let's decide what layers through been removed and what you know, how much space will be freed is also available.
00:15:31 [W] So when you hit the dry run and we we just Mark the layers that are candidate to be removed and calculate the
00:15:46 [W] Why the hinder for the L mean to you know, let him know how much space will be freed if he run the PC right now now this is a very rough estimation because this is a non-blocking DC. So images may be pushed when the
00:15:53 [W] You're going to see now if I you know trigger the DC now you can see the top is scheduled and it's running you can notice that there is no
00:16:06 [W] Bar thing that Harbor is in read-only mode and at the same time I can do a darker push to my Harbor instance. Well, it's, you know being garbage collected.
00:16:20 [W] It's still running.
00:16:23 [W] And pushing is in progress.
00:16:27 [W] It's an instance iwi.
00:16:29 [W] so that it's a bit slow.
00:17:36 [W] Okay, you can see this Cobra clutch, and it's also finished if we see the lock you can see what layers are removed and there is a actual you know size up to storage that is
00:17:51 [W] Anything what layers are removed?
00:17:40 [W] This is you know, big Improvement for the enemy and so that they will not need to worry about you know, their developer not being able to put images doing GC Next
00:17:56 [W] we may improve, you know by we are considering to improve the performance of DC by you know, doing the deletion in parallel, but this is not that an issue because it's
00:18:06 [W] All right, if the TC runs a little bit longer we consider this. Okay.
00:18:05 [W] That's all that's all my partner Alex.
00:18:07 [W] Thanks. Thank you, Daniel.
00:18:10 [W] I'll continue with the 22.
00:18:12 [W] So let me make sure it's still recording.
00:18:15 [W] Yes.
00:18:16 [W] Let me share my screen.
00:18:25 [W] Can you see my screen?
00:18:28 [W] So let's continue.
00:18:34 [W] So thanks Daniel for that for that demo Switching gears a bit now.
00:18:39 [W] I'm going to talk about the upcoming to point to release and some of the things that are being planned and being worked on.
00:18:46 [W] The first one is metrics and observability.
00:18:50 [W] this is really just a fancy way of saying we're going to be supporting Prometheus still the goal is to monitor Services deployed actions performed as part of your target deployment.
00:19:03 [W] Expose those metrics through an HTTP endpoint for Prometheus.
00:19:08 [W] And so if you have Prometheus already set up in your environment, it's already part of your stack. You can then scrape whatever data you want often employing.
00:19:18 [W] The this is really just a fancy way of saying we're going to be supporting Prometheus still the goal is to monitor Services deployed actions performed as part of your topper deployment and expose those metrics
00:20:17 [W] Meet divide it into several layers right at the very bottom you have the platform, which is your notes level information and you can monitor your resource consumption.
00:20:27 [W] So CPU Ram disk basic event logging health status of the of the the deployment as a whole and then you have the container orchestration layer which in the case of kubernative school provide monitoring
00:20:43 [W] All the pots deployed in your cluster.
00:20:46 [W] So here you can see in this diagram.
00:20:48 [W] We have some of the main parts that make up the harbor cluster yours Harbor coredns. There's Harbor Bridge is 3D be there's job service, but there's you know a bunch of others so that the web portal its own nginx
00:21:03 [W] Stop service, but there's you know a bunch of others. So the web portal its own nginx has its own charm Museum, if you're using trivy or Claire image scanners, they have their own
00:21:13 [W] Singing Chevy or clear image scanners.
00:21:15 [W] They have their own and then finally, we haven't climbed a tree at the application layer, which is, you know, basically the relevant registry operations and thing that the harbor API provides is a potential candidate here.
00:21:30 [W] And we can extension expose aggregated Statistics over some period so looking at the number of uh, poles or number of images pushes image deletions.
00:21:40 [W] Also looking at top images repositories projects being requested possibly looking at a number of push errors or delete errors or authentication errors and you know any other statistics that could be useful for
00:21:55 [W] Detecting open your mouth you three, like users number of users logged into a particular instance number of failed attempts unique IPS number of image requests served in some period requests and flight number of applications.
00:22:11 [W] So this is still being actively worked on I think the pr to the proposal in our community repo if you have any questions or comments or want to contribute to this work, please please make comments on the pr or just reach out to us.
00:22:32 [W] So we've also gotten a lot of requests to deliver system-level robot accounts, which is a robot account scope to the harbor instance level so has access to multiple projects as opposed to the current robot implantation,
00:22:47 [W] To a particular project, right? If you're familiar with that how that works.
00:22:41 [W] You're creating the robot count from within the project configuration page right now.
00:22:45 [W] And you know, that's that's also understandable projects go permissions.
00:22:50 [W] It becomes an issue when an image in one project is expected to extend an image and the different projects vary which is often the case. If you're using heart images within Harbor as part of your soccer field and you're executing the dock appeals and
00:23:05 [W] Stages each from instruction would use a different base image and built iteratively. So that's exactly where we're going to be delivering in the to point to as the system I mean Persona
00:23:13 [W] to create a system level robot accounts in addition to project level robot accounts, which are only available to project elements and then you know, you can choose the projects that that robot count that particular robot count has permissions to
00:23:23 [W] Green Dot the creation of the robot account you can also choose the particular set of actions actions that you can perform.
00:23:26 [W] So like pushing the image or pulling image deleting images and much more and then you'll be able to change the set of projects and the set of actions at any given time without having to recreate a
00:23:41 [W] With a new token, right which is the experience right now.
00:23:41 [W] So if that's Hilton is hard-coded somewhere into your Ci or it's being used to construct a pole secret and used to be manually recycled right now.
00:23:50 [W] So we're trying to kind of we're trying to remove this kind of friction. So that changing the project scope or changing the permissions of that robot will not impact your CI and anyway, so again, this is being actively discussed
00:24:05 [W] I've linked to PR as well to this proposal in our community repo. If you have any questions comments, please share your feelings on the pr if you have already implemented your own solution would be really interested in hearing that as well.
00:24:20 [W] And finally, if you've been tracking our progress or attended any of her community meetings over the last six to 12 months really, you know that we've been working on an operator deployment of Harbor that will run it as a kubenetes cluster sort of similar to
00:24:35 [W] now but it has certain advantages when it comes to day two operations and it's also much more intuitive for performing some of the more heavy duty operations, like upgrades redeploys backups and restores
00:24:45 [W] To give a little background this really started with ovhcloud.
00:24:41 [W] I want to give a shout-out to ovhcloud kick-starting this effort and doing a really great job ovhcloud team built the first version of the harbor operator and you can find this as the core operator rebuilt undergo Harbor project on
00:24:56 [W] But it doesn't include certain depends services like databases redis cash or its storage because you know some vendors already have those Services running as managed services and there perhaps already deployed in
00:25:09 [W] Highly distributed or highly available Manner and that makes sense, right?
00:25:10 [W] That's that's definitely one use case that we have to we have to cover but you know for the other users that are perhaps not as the advanced that's looking for an all-in-one to Pullman that comes with all the components that Harbor needs to run we
00:25:25 [W] The harbor cluster operator and that will basically deploy Harper with all the depends services like database read as cash storage and deploy these in a chamber mood.
00:25:33 [W] So we don't have to Deep dive every term every aspect of this diagram, but the key takeaway here is that you can see that in this diagram. There is a harbor harbor cluster cri-o.
00:25:47 [W] Very top right.
00:25:47 [W] So there's a there's a harbor cluster controller.
00:25:49 [W] That's essentially managing all the services needed for the registry and the cluster operator custom resource encapsulates the core operator custom resource that I just talked about as well as the custom resources.
00:26:03 [W] for all the other individual components
00:26:06 [W] And so the the harbor cluster is basically watching over everything and continuously reconciling to make sure that what is running is what is actually specified in a CRC spec. And so if there are any
00:26:22 [W] You can see that in just a grey matters Harbor Harbor cluster.
00:26:23 [W] Cri-o the very top right so there's a there's a harbor cluster controller.
00:26:26 [W] That's essentially managing all the services needed for the registry and the cluster operator custom resource encapsulates, the core operator custom resource such as talked about as well as the custom resources for all the other
00:28:29 [W] Then it can automatically redeploy those services.
00:28:32 [W] So now for anyone who's wondering about high availability in the sense of multiple Harbors Harbor clusters across different data centers, perhaps in different availability zones, even we do have a story in the
00:28:47 [W] That as well but that's sort of outside the scope of the harbor cluster operator.
00:28:54 [W] I know that there's their people have been asking about it.
00:28:56 [W] So I just want to address it and say, you know, this is something that we are aware of and it's something that we're working towards and so for each of these components you can customize the spec for that ci/cd essentially, right? You can specify the number of replicas you can
00:29:12 [W] My cash for the red is cash or for the database.
00:29:10 [W] You can choose to use an external cash or you can declare in class and run that in a chain mode.
00:29:16 [W] So we have a really detailed proposal detailed meeting notes on the progress for the cluster operator under to go Harbor project.
00:29:26 [W] So, please feel free to check that out and share your thoughts.
00:29:30 [W] You know, we're still wanting or feedback on the design because we will only have released the very first cluster operator.
00:29:37 [W] Version 1.0 by the time this recording the shared.
00:29:45 [W] So that's everything we want to share related to the 2.1 as well as the upcoming 2.2 just a quick word on collaborating with us and how to get more involved in the community.
00:29:55 [W] Please follow our Twitter. If you want to be alerted to any of the latest announcements on releases community events collaborations or anything Harbor related.
00:30:06 [W] We're still holding the bi-weekly committee meetings one for you as time zone and one for a pack.
00:30:11 [W] This is where we have something to feature demos like the ones that Daniel just did and we highlight some of the latest developments in the project in anyone can come to resume meeting and ask questions or share your experiences around
00:30:26 [W] Alerted to any of the latest announcements on releases community events collaborations or anything Harbor related.
00:30:30 [W] We're still holding the bi-weekly committee meetings one for you as time zone and one for a pack.
00:30:36 [W] This is where we have some to feature demos like the ones that Daniel just did and we highlight some of the latest developments in a project in anyone can come to resume meeting and ask questions or share your experiences around
00:31:09 [W] Um, you can find at the detailed meeting notes in the meeting details in a readme for the harbor project on GitHub.
00:31:20 [W] And finally, we do have a demo deployed that anyone can just go on and give it a try get familiar with the the UI create a project add users push and pull images to and from that project.
00:31:34 [W] project. So then we'll tackle Harbor dot IO.
00:31:40 [W] So that's all I have for today.
00:31:45 [W] Thanks, Daniel for sharing a demo and then you know, we'll take any questions for the remaining five to ten minutes.
00:31:52 [W] thanks everyone for staying with us so far.
00:32:19 [W] Hey, so we have I think five or ten minutes for Q&A.
00:32:24 [W] I've tried to answer some of the questions in chat and you know, feel free to I think there's a way for you to raise your hand or in mute yourself and ask questions.
00:32:49 [W] Hey, so we have I think five or ten minutes for Q&A.
00:32:54 [W] I've tried to answer some of the questions in chat and you know, feel free to I think there's a way for you to raise your hand or and mute yourself and ask questions.
00:33:06 [W] If not, you know, I'll go over whatever remaining questions.
00:33:10 [W] There are in chat.
00:33:15 [W] So, let's see. The first one is
00:33:20 [W] Dheeraj, I'm sorry if I mispronounce your name, huh masks to explain proxy cash since Docker is rate limiting is limiting polar array.
00:33:31 [W] Yeah, it's so.
00:33:33 [W] You know, we spend a good portion of the presentation talking about proxy cash.
00:33:38 [W] We really worked on this prior to dr. Helps now summon on rate limiting but sort of in getting in anticipation of those developments because people have been coming across those problems for a while now,
00:33:54 [W] Cash since Docker is rate limiting is limiting polar array.
00:33:59 [W] Yeah it still.
00:34:02 [W] You know, we spend a good portion of the presentation talking about proxy cash.
00:34:07 [W] We really worked on this prior to Docker Hub snouts Matan rate limiting but sort of in getting in anticipation of those developments because people have been coming across those problems for a while now,
00:34:44 [W] Your Hub has Nuri limiting policies that went into effect on November 1st of this year.
00:34:50 [W] I believe it's 100 Anonymous poles per six hour period in 200 authenticated pools per six hours.
00:35:00 [W] So they really know cover their bases and the purpose of the proxy. I chose not to get around.
00:35:07 [W] Hubbard limiting rights to help you mitigate to some extent and not needlessly pull images that are already that you've already.
00:35:14 [W] Pulled so if the if not on the image blobs have changed Harbor is only doing ahead request to compare to manifest to see if the cache needs to be updated and then, you know served the cache copy
00:35:29 [W] Let's sleep or images that are already that you've already pulled.
00:35:33 [W] So if the if not on the image mlops have changed Harbor is only doing ahead request to compare the Manifest to see if the cache needs to be updated and then, you know served the cache copy if it
00:36:01 [W] And if it does then it will have to trigger the red limiter to pull this new image blocks and then serve the so I can help you alleviate against dr. Humphrey limiting, but it's you know, it's darker.
00:36:17 [W] Limiting is there enough our purpose right?
00:36:20 [W] And so we want to be we want to work within those constraints in fira Street be respectful of their their policies as well.
00:36:31 [W] Yeah, the account used for the proxy cash is basically it's your Docker Hub account. Right when you set up a proxy project. You have to select an endpoint.
00:36:43 [W] That's the end point for the registry that your poxy you for.
00:36:48 [W] And so we set the end point you have to put in your AK your access keys for that Docker Hub account.
00:36:57 [W] And then, you know the images that you see it through the proxy project that the proxy project has full access to that's dictated by.
00:37:07 [W] The images that you have access to based on your credentials for that Docker Hub account.
00:37:22 [W] I don't know the status.
00:37:23 [W] We haven't really talked about supporting Anonymous find for ldap, you know, if you feel there's a need for please submit a ticket on GitHub now, we will usually go over any incoming tickets
00:37:38 [W] So we'll make sure to look at the triage any tickets within within last seven days. So
00:37:47 [W] Know if there's a change in the Upstream.
00:37:49 [W] It doesn't automatically it doesn't automatically pull so it's not it's not pulling the Upstream for changes. It's just that every time there is a poor request it will
00:38:01 [W] It will check the Upstream to see if the image needs to be updated, but it's not doing that automatically.
00:38:13 [W] So we are talking about integrating harberger with gitlab.
00:38:17 [W] I'm assuming you want, you know, like git commits or any kind of changes to the source repo and gitlab to somehow trigger a build of the image and then
00:38:32 [W] Um, I believe that's something that gitlab pass on that's a functionality that gitlab has Harbor doesn't really deal with build so far.
00:38:29 [W] We've entertained the idea of adding build triggers into Harbor, but it's not in the media roadmap, but I can see I know some users have built a workflow basically any time you do a git commit to a specific
00:38:44 [W] Branch it will spit out an image with a certain tag and then push that image onto Harbor so I know people are doing that and then in between, you know, you can use harbor web hooks to to fire notifications telling you that
00:38:52 [W] Image onto the registry or you scan an image and has such and such vulnerabilities Etc.
00:39:03 [W] Right. So Harbor has one ability skinny building to it. So you would potentially do the building of the image off Harbor in gitlab or in some other 5cm Source control management, and then push the image to Harbor and the harbor can
00:39:19 [W] You can scan your image.
00:39:22 [W] and then generate vulnerability reports
00:39:31 [W] so all
00:39:35 [W] I'm not sure what the last question is.
00:39:38 [W] Is is referring to all requests to Docker look to come from that user.
00:39:47 [W] Sorry, I'm not.
00:39:48 [W] I don't know if you can expand on that and Chad little bit.
00:40:14 [W] Are there any other questions or comments?
00:40:16 [W] You can also talk about your experience using Harbor and what you'd like to see Good The Bad anything?
00:40:45 [W] Sorry, I'm not.
00:40:46 [W] I don't know if you can expand on that and Chad little bit.
00:41:12 [W] Are there any other questions or comments?
00:41:14 [W] You can also talk about your experience using Harbor and what you'd like to see Good The Bad anything?
00:41:47 [W] There was a question earlier on how to configure Harbor is a transparent proxy mode.
00:41:51 [W] I just wanna talk about that a little bit essentially right. Now. You have to change your your dr. Pol commands in your palm manifests to point to Harbor Nats the harbor instance that's acting as a proxy you cash for your Upstream,
00:44:06 [W] Are there was a question earlier on how to configure Harbor is a transparent proxy mode.
00:44:10 [W] I just want to talk about that a little bit essentially right now. You have to change your your dr. Pol commands in your palm manifests to point to Harbor Nats the harbor instance that's acting as a proxy you cash for your Upstream,
00:44:25 [W] That's what it that's what's meant by transparent proxy proxy mode. So you don't have to change her your Pokemons in Europe on manna-fest and you know pulling against Docker Hub will go through Harbor proxy cash instead
00:44:40 [W] that would require deploying something basically outside of Harbor to be able to observe that change right and it wasn't some kind of mutating why poke to take that incoming polar Quest and then translate it to
00:44:55 [W] Some kind of mutating why poke to take that incoming porec West and translate it to to a harbor URI and also be able to you know work with image full secrets and make sure you have the right access.
00:45:09 [W] I and also be able to you know work with image full secrets and make sure you have the right access for those images.
00:45:17 [W] So that's something we're looking into.
00:45:19 [W] That's probably going to be if we do deliver in 2.2. It's going to be something it's going to be another rebuilt inside under to go Harbor project that you'll have to deploy.
00:45:41 [W] All right, and I think I've answered all the questions.
00:45:54 [W] Jamie Roberts masks working on Harbor diploma right now.
00:45:58 [W] Should I take a stab to Cluster operator So the plan was to get the cluster operator ready in time for this session, but it's actually been delayed a little bit.
00:46:07 [W] So if you go on to get hooked and look at the cluster operator, it's not it's not released yet and there's an artist CL but the official version will be released.
00:46:18 [W] I would say before the end of the year. So towards maybe a seccomp.
00:46:23 [W] After a week of December is when you'll be able to use it.
00:46:26 [W] So for right now if you wanted to play Harbor is a kubenetes cluster, please use the helm charred and very soon.
00:46:34 [W] We'll have the cluster operator ready for you.
00:46:37 [W] Third the operator is going to be one of one with Harbor OSS, right? And so the first version of the cluster operator is going to be based on Harbor 211 and for every subsequent patch release and
00:46:51 [W] I have an operator for that just like we have for helm.
00:47:40 [W] I thank everyone for coming to talk.
00:47:46 [W] We've done this for a number could be conferences now and we've seen more and more users come to these and so, you know, really really happy that you guys are are involved in and curious.
00:48:02 [W] watch for the next version 2.2 which is going to be
00:48:02 [W] we're thinking either end of January or beginning of February and then the cluster operator that talked about will come out before the end of the year. Most likely.
00:48:13 [W] All right.
00:48:14 [W] Thanks everyone. Have a good one.
