Banking on Kubernetes, the Hard Way, in Production: ZAWU-3458 - events@cncf.io - Wednesday, August 19, 2020 7:40 AM - 49 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:00:00 [W] Hey Welcome to our presentation banking on kubenetes the hard way in production.
00:05:38 [W] So we work at a company called Monza which is a bank in the UK and we absolutely love kubenetes. We've been using kubernative since the very early days since the one point two days when we tell people at meetups and
00:05:55 [W] Run, our own cabinet is clusters.
00:06:00 [W] We self manage our own kubernative clusters.
00:06:09 [W] We generally get met with looks of incredulity and questions of like, what wait why why are you doing that?
00:06:15 [W] And we realize that there are not very many talks out there about people who actually runs off a stewpot a simple action.
00:06:23 [W] They can most of the most of the content out there is about using managed services or can at we clusters on your kind of a laptop and we thought we'd really like to
00:06:28 [W] to kind of share our journey of self esteem talk about some of the benefits we've got and but also talking about why like if we were starting from scratch today, we've probably want to go for a minute service.
00:06:38 [W] So that munzo our goal is to make money work for everyone we deal with the complexity of making money management easy for all of you for those who haven't heard about munzo before we are a fully licensed and regulated UK bank
00:06:54 [W] Branches, you can manage all of your money and finances by the app.
00:07:03 [W] We hit a milestone or four million customers earlier in the year and that number makes bigger than some major institutions in the UK that have been around for over a hundred years.
00:07:14 [W] We also have these rather striking hot Coral debit cards, which you might have seen around the even glow under UV light.
00:07:17 [W] So hi. My name is Sal and I'm joined today by Miles.
00:07:29 [W] We are both engineer's on Monza and we spend our time working on the underlying platform pairing the bank and we think about all the complexities of scaling our infrastructure. So that Engineers enough teams can work on actually kind of building and running the bank.
00:07:37 [W] So just to give a quick outline of what we're going to go through today.
00:07:49 [W] Well, let's start off with our kind of like Journey self-hosting like why and kind of how we're doing this and we talked about some of the benefits that we've seen from running around cluster, then we'll go on to
00:07:57 [W] Of when so the self wasting didn't work so well for us and finally like would we do this again if we were starting in 2020?
00:08:08 [W] How did we get started by self hosting our own kubernative cluster getting a banking license in the UK takes a really really long time.
00:08:22 [W] We had some time to make some up front and long term architectural decisions.
00:08:27 [W] We wanted to get these right because nobody really wants to replace the fundamental technology that underpins a running back.
00:08:32 [W] We wanted our systems to be highly extensible scalable resilient and secure and naturally we chose microservices as a natural fit.
00:08:38 [W] Most of those things we've really gone in on Microsoft says this graph shows how the number of services were running has changed over time and we now have over 1600 Microsoft has underpinning the bank. I think this describes
00:08:54 [W] Octet strategy and once I write if you look if you look at a graph like based on that Trend, I think we're probably going to have more microservices than the number of atoms in the known universe in about five years time, but we'll see.
00:09:08 [W] we'll see how that goes. Here's a simplified architecture diagram. Anyway, every one of these 1600 watts is an Interpol to microservice each one of the like the graph edges is a connection between microservices
00:09:22 [W] Number of microservices allows us to be really flexible in how we scale. Our services allows us to be flexible in how we organize teams and Engineers each microservices like its own kind of bounded context has its own responsibilities.
00:09:36 [W] Wind the clock back to 2016 when we had just started out building a modern banking anger infrastructure.
00:09:48 [W] We knew the platform to deploy run and operate these microservices.
00:09:52 [W] They started to learn started out with Mason has a marathon but we quickly run into some of the limitations and lack of features.
00:10:03 [W] Let's just say so we decided to make a very bold and strategic but on a new open source project that just came out called keep a Nettie's I'm time keeping it.
00:10:08 [W] Tony just really started like a 1.0 version in mid-2015 and there wasn't really any kind of like automated tooling to spin up a cluster. The worst one was a nice kind of like manage key
00:10:23 [W] I told him it was the like Arch Linux of Open Source or castration platforms.
00:10:29 [W] You have to do everything yourself. And if you broke it, at least you get to keep all the pieces. Let's go into some of the benefits we've seen from hosting our own kubernative clusters.
00:10:42 [W] So firstly over four years of operating kubernative ourselves.
00:10:48 [W] We've picked up a lot of expertise and understanding of how cabinet is Works under the hood when we're supporting other engineer's at Monza way but to give valuable advice.
00:10:53 [W] And resolve, you know when things go wrong, really really quickly.
00:10:58 [W] thanks to this understanding that we've built up we have the ability to dive deep into the stack and fix problems ourselves.
00:11:11 [W] One of the early example of this that we have is with CPU throttling.
00:11:16 [W] So it kind of makes this problem in some of our base latency-sensitive Services. We're saying really high kind of like tail Layton sees that 99 percentile and we kind of really
00:11:26 [W] Into this and found that these Services were using a lot of CPU and they were actually being kind of paused by the kernel 400 milliseconds GT how CP for something works and this hundred milliseconds figure is actually a
00:11:38 [W] And the colonel and keep Nats is used to hard code this and didn't allow us to kind of extend this.
00:11:52 [W] So after we cut this down where you kind of open the Nikki discuss with Community proposed to fix and we came up are kind of like our own own fix for this and we were able to test this ourselves run it in our a cluster
00:12:02 [W] We like came up are kind of like our own own fix for this and we were able to test this ourselves run it in our a cluster despite having the capabilities of so fasting.
00:12:05 [W] This ties in with one of the other benefits is that we have the ability to completely customize our own communities experience.
00:12:18 [W] We were mocking Arch Linux earlier, but arch really does let you easily customize and tune every aspect of Linux to your liking and by self hosting a kubernative cluster you gain the same flexibility we've hit numerous
00:12:29 [W] We've had numerous scaling issues and problems with our setup that we were able to fix by tuning API server Flags while investigating and fixing bottlenecks in components like NCD, we've been able to integrate custom components quite easily like the vertical poddisruptionbudgets.
00:12:57 [W] Without having to reconfigure the entire control plane components, but that hasn't been my experience over the past couple of years.
00:13:06 [W] It's only now that the kubernative project is moving in that direction where this splitting off into more and more components almost like our microservices, but one of our best examples of where self-hosting has really helped us,
00:13:19 [W] Even at is evolving very very quickly.
00:13:28 [W] And one thing we have got good data is doing complex upgrades and migrations and this particular example.
00:13:35 [W] We're really proud of is doing a rolling migration of the overlay Network on a life cluster.
00:13:44 [W] So when we started first eating give notice we decided to use the flannel overlay Network, which was probably the most popular Network at the time and a couple years later.
00:13:48 [W] We were still running it and we are still running it in.
00:13:50 [W] The like the really slow vxlan mode.
00:13:57 [W] If you haven't come across this this essentially works by wrapping all your layer to traffic in UDP packets, but crucially the wrapping and unwrapping happens via flannel proxies, which run in user space
00:14:08 [W] Play and eventually we kind of were running into the limits of this.
00:14:24 [W] We also quite Keen to start eating there were policies to lock down traffic between different pods. And Calico seemed like a natural fit to both solve the problem of our networking being slow and low bandwidth and two studies in our politics.
00:14:29 [W] We need to migrate from flannel T, Calico.
00:14:33 [W] Now the the normal kind of sane way of doing this is to spin up an entirely new cluster with the new gun a network overlay and shift your traffic across to it.
00:14:47 [W] But this was this would have been pretty tricky for us each has some unique constraints at the time.
00:14:50 [W] And firstly we had some stay for workloads in the cluster and at the time spitting mean he's workloads across two clusters and kind of balancing between them wasn't a very kind of easy problem to solve. Secondly.
00:15:05 [W] have some workloads which persistent connections to payment schemes and these would have also been quite tricky to split across the two clusters without downtime and as a bank planned downtime is something we really want to avoid at all costs.
00:15:20 [W] Is quite frankly. It should be acceptable as a bank to tell customers.
00:15:26 [W] You won't kill to my access your money between these two hours.
00:15:28 [W] You won't be able to go to an ATM and withdraw money.
00:15:30 [W] So for us doing the kind of T cluster approach was pretty tricky.
00:15:37 [W] However, we do find a way to run both overlay networks in the same cluster at the same time the kind of flavor simple description of this I guess is that we deployed two different groups one wear flannel and one with Calico
00:15:49 [W] Like the ranges and every node on a cluster was configured to be able to root 2, I think any any other node regardless of what overlay network was and this is pretty ideal for us because we could slowly kind of like ramp up the number of
00:16:05 [W] Not and like tuned down a number of like flannel notes and quickly roll back by going the other direction and we run into any issues and I think I experience the self hosting and
00:16:20 [W] I can contact with gained over the years was what allowed us to do like like such an impressive kind of technical V.
00:16:28 [W] So you you're probably watching this and think that it all sounds too good to be true so I want to give a little bit of a war story to add some balance and perspective about when things don't go so well so towards the end of last
00:16:44 [W] We announced the completion of a major infrastructure security project called Network isolation previously.
00:16:56 [W] It was possible for any service running in our cabinet is cluster to talk to any other service was the vast majority of services are built internally by engineers at Mondo and our peer review to make sure that they are secure and safe.
00:17:06 [W] Move to a model where the networking was much less permissive.
00:17:16 [W] We wanted services to explicitly allow specific traffic and deny all other traffic and to do this. We leverage kubernative Network policies and built a whole bunch of turning on top of them.
00:17:25 [W] essentially what the tooling does under the hood is each service gets a network policy only allowing traffic by other services, which have a particular label intending egress to a particular service under the hood.
00:17:36 [W] We use Calico. So Calico enforces the network policy by generating a bunch of Ip tables rules to enforce the network policy.
00:17:49 [W] So prior to rolling out these Network policies across all of our services in enforcement mode.
00:17:54 [W] We wanted to dry run them to make sure that we caught all of the services talking to each other.
00:18:00 [W] We wanted to avoid an incident where we enforce there were policies and accidentally block some unconfigured but legitimate traffic that should have reached is a its destination to do this. We use a knife.
00:18:10 [W] Tables feature to log when asset were when a set of network policies iptables Roars hadn't already been accepting existing traffic.
00:18:20 [W] So we incur did this into our deployment pipeline for services.
00:18:24 [W] So as new Services were being deployed by engineers.
00:18:26 [W] With correct track correct. Tagging of all traffic that should be going in and out between services.
00:18:48 [W] This naturally meant that we started seeing snow Rios where packets would have been dropped had the network policies been and enforcement mode.
00:18:53 [W] So this is great.
00:19:04 [W] The logging is working and we can keep rolling out more and more refined policies, but the correct labels across all of our services and see this graph tend towards zero once we had coredns verything. It was a great way to
00:19:06 [W] to validate that we had captured all of the services.
00:19:13 [W] We also had the raw log data stored in our in our logging infrastructure so we can slice and dice the the origin of traffic.
00:19:19 [W] So what we found one day is once a few Services had been deployed with this network policy change in logging mode.
00:19:30 [W] We started seeing a big increase in sporadic networking issues within our communities cluster.
00:19:37 [W] We saw effects of communicating between kubernative nodes and components within our communities cluster saw effects talking to components outside of our kubernative cluster.
00:19:47 [W] So it turns out that running the services which had never
00:19:49 [W] A policy about froze deployed were unable to keep up with the workload of logging and processing these iptables rules and it was leading to CPU starvation in the colonel just a little bit of background context when the colonel receives a network packet
00:20:04 [W] Hands it off to a kind of Sub sub system code sot. I accuse soft irqs our kernel threads and there is a by default 1 / logical CPU and that's where we're
00:20:20 [W] Assessing happens including the evaluation of iptables rules.
00:20:28 [W] We were essentially exhausting these kernel threads by putting down a log roll.
00:20:32 [W] This was compounded because we were using EPS as our root volume. So essentially we were logging over a network attached storage on these instances kernel threads where it's essentially been blocked waiting for the network to
00:20:46 [W] Logging while still bugging this incident. We were considering the whole bunch of fairies.
00:20:55 [W] We run on AWS.
00:20:59 [W] So we were thinking this could be a networking issue on a diverse aside a diverse will really helpful in real time and told us immediately that things are looking healthy on there. And once the packets were in the AWS networking infrastructure.
00:21:09 [W] They were making their way reliably on the other end.
00:21:14 [W] It was just a matter of getting into the AWS networking stack. We had multiple parallel.
00:21:17 [W] It's two streams of Investigation during this incident and it was only when we looked at the IP tables rules that we realized that the logging was a potential Theory and we were exhausting all of the all of the kernel threads the
00:21:32 [W] to the issue that we were seeing only after the fact
00:21:36 [W] so we had to abandon the logging as our default mechanism to capturing all potential packet drops, but the logging did give us some really useful information.
00:21:47 [W] So we want to tip the right balance about when we would turn on the logging because at this point we were running fully on Calico we were able to do we were able to re-evaluate and do a to phased approach where we use Calico metrics.
00:22:00 [W] And we wrote a custom open source tool which was able to take those click on metrics and put them into Prometheus.
00:22:09 [W] We call this tool Calico accountant and it was able to check the rate of packet drops. And once the rate of packet drops had been had gone down to an acceptable level we were able to turn on the log mode
00:22:23 [W] Check that the last few stray packets that were being handled correctly.
00:22:32 [W] We wanted the raw logs because they gave us a much richer information on the source of traffic.
00:22:40 [W] So we kind of speak in a bit about the benefits of self wasting and we give an example of where they with maybe shot ourselves in the foot by self-hosting and so your own balance.
00:22:51 [W] Let's say we were building a new kind of platform from scratch in 2020 and we want
00:22:55 [W] to use scuba Nettie's would we sell faced again?
00:22:57 [W] I'm and I think there's a there's a few things to consider here.
00:23:04 [W] So first of all, running your own cluster Is Now by easier than ever.
00:23:08 [W] It's no longer like and of our clinics.
00:23:17 [W] You have a like a bunch of really useful tool ding like keep ADM is a lot of work going into things like cluster API and a moment to kind of create this dream where you can just like run a few commands and get a production ready cluster
00:23:23 [W] I say it is easier to sell face nowadays, but at the same time managed Services have also gotten a lot better and of course being managed Services, you lose a bit of control and flexibility.
00:23:42 [W] You're not able to kind of make Fleet week and configure your setup to kind of every degree.
00:23:52 [W] but you do get the benefit of like a number of really really smart and experienced Engineers you like have the lake.
00:23:55 [W] like the wealth of experience running tens of thousands production clusters for customers, and I've also gotten really good at keeping on top of the deepness really schedule handling things like upgrades and they this is
00:24:08 [W] Build and run and maintain yourself if you run your own cluster.
00:24:13 [W] So in conclusion, if we were starting today, we wouldn't be running our own cluster the offerings from plowed providers like AWS and Google Cloud brings so much tooling and expertise which we have had to build
00:24:31 [W] I look for example at all like at our existing cluster configuration and it has been iterated on constantly with learnings and learnings from others.
00:24:47 [W] And that's not something that you can have immediately on Day Zero if you're if you're starting afresh and if you go about it yourself, nevertheless, we've gained some incredibly valuable expertise by running our own cluster when we
00:25:00 [W] Provide offering we can quiz them on how they handle things like scaling at CD and handling not lots of network policies based on our experience in the past.
00:25:13 [W] We can identify these constraints up front as well as we can also spin up our own clusters.
00:25:19 [W] We can have a hybrid setup where we can spin up our own clusters relatively easily based on the existing configuration that we have iterated on and make sure that kubenetes is is
00:25:30 [W] Is fit for purpose and potentially send more patches Upstream when we find scenarios and workloads that are not appropriate.
00:25:44 [W] Anyway, thank you for coming along and listening to our talk. We hope you enjoyed a
00:25:46 [W] Incredible questions. If we do run out of time, I'll also be in the slack channel to - operation to - Cube Khan - operations where I'll be more than happy to answer any other questions.
00:26:15 [W] From the from the top is ones are 100% in the cloud.
00:26:23 [W] Are we just using ec2 or GC to host?
00:26:25 [W] We do have a few to physical data centers where we connect to a payment processors because we have built payment gateways in-house so connections to the faster payment scheme. And also most Cod those do not run
00:26:38 [W] Is in the data center, it's something that we are looking into but we actually run the minimum amount of compute in those physical data centers that we manage and essentially route all of the traffic onto our AWS infrastructure.
00:26:54 [W] It's far easier to make changes and deploy new updates to software.
00:27:08 [W] That is our primary Aim. So we have a physical connection between our data centers and our database infrastructure.
00:27:14 [W] Do we use the open source Calico or tigrerra Enterprise?
00:27:15 [W] We use the open source version of calico.
00:27:18 [W] found it to be perfectly fit for purpose one of the big benefits of you know, the Calico Community is everyone is extremely welcoming and there's a
00:27:27 [W] a wealth of information online.
00:27:31 [W] We've not really found the need to go for Enterprise, but they do build pretty incredible software.
00:27:40 [W] So, you know never say never if we do want something that is a bit more custom than what open source Calico provides or if there's something in the Enterprise plan that that might be suitable for us then we would
00:27:49 [W] Explore that.
00:27:55 [W] We've had a few questions about compliance and PCI on Cuba Nettie's.
00:28:00 [W] So we were actually one of the first banks in the UK to run banking infrastructure on AWS.
00:28:13 [W] Yeah. There's a few like old stories from some of the original people that set it up where they quite literally had to had to beg the agencies that enforce this in the UK to allow us to
00:28:20 [W] to experiment and running in the cloud because we knew that we could move significantly faster if we did as an organization, and essentially we've had to work very very closely with the regulator and also,
00:28:35 [W] Horse PCI and all the components to make sure that they are up to speed on community's infrastructure and they understand what is going on under the hood.
00:28:51 [W] We want to make sure that they are applying the same rigor and the same back enforcement in the cloud. We don't want to pull the the sack over anyone's eyes. So to speak and you know, a lot of there was there's a lot of parallels between
00:29:02 [W] Structure and what you'd run with kubernetes so example in physical infrastructure, you might have an appliance which provides a firewall and you know, you might use that for your applications and you might want to show that your firewall is correctly configured in the communities.
00:29:17 [W] Similar parallel with network analyses you want to make sure that your network policies are being enforced and that they are they are configured correctly and they are they are being utilized appropriately.
00:29:33 [W] So, you know, these are just layers of abstraction and ultimately what they want to see is that you are you are utilizing the spirit of you know, what is being described in in these in these documents for what they want to achieve.
00:29:46 [W] know, it's not the letter of the law. They're not saying you need.
00:29:50 [W] I have a physical appliance that does firewalling and that's the only way they want to see that you are you are you are following the spirit of what it needs to achieve and to make sure they have isolation between systems
00:30:03 [W] Stem is compromised.
00:30:10 [W] It doesn't that go into your your payment gateways which handle really sensitive data.
00:30:18 [W] There's been a good question about how many services we run in our in our cluster. So we have one single production cluster and we run all of our microservices their service 1600 Microsoft Office has these are all building in in go and
00:30:26 [W] Goods of nodes and we've been running with the setup for quite some time and that ties in really nicely with some of the questions on like servicemeshcon how componentconfig mc8 with each other so initially we started off with linkerd e linkerd E1
00:30:41 [W] Meaning that for quite some time back when you know linkerd e had originally launched and joined the cncf a few years ago. We migrated to Envoy Hazard as a servicemeshcon troice
00:30:57 [W] we migrated to Envoy mostly because of performance related reasons and also some of the flexibility that Envoy could give us with its discoverability apis, and we've built some Integrations on top like the way we do egress gateways, so
00:31:13 [W] Escape ways. So one of the big other security measures is to make sure that we have appropriate measures for talking to components outside of the cluster.
00:31:26 [W] So think like, you know, Google apis or Amazon apis and and stuff like that and that we are we are not egressing traffic to any random locations. So it'd be really difficult to export rate data.
00:31:37 [W] So we've been able to leverage Envoy and components like called DNS to be able
00:31:43 [W] all to Route traffic appropriately and deny all other traffic that shouldn't be being Equus to random places.
00:31:53 [W] Let's see. What other questions are there.
00:31:58 [W] Do we run databases on kubernative so our database of choice for the vast majority of our microservices is Cassandra.
00:32:09 [W] do not currently run it on communities, but there's been quite a lot of exciting workloads.
00:32:12 [W] To make Cassandra more kubenetes aware. So for anyone who has run Cassandra in the past and like many other leg state for systems like databases one of the one of the key components is that
00:32:27 [W] IP addresses and host names and stuff like that need to be fairly static.
00:32:36 [W] They it becomes quite difficult to manage under the hood with in the underlying database systems. When IP addresses are constantly changing because they use to identify identify hosts. Even if
00:32:47 [W] Lying data underneath they changing a lot of that in a lot of these database systems because it has been a need to run these database systems on kubenetes and a desire from various companies, and
00:33:03 [W] To run these database systems on kubenetes and a desire from various companies and you know, we're really excited to see the direction that the Cassandra Community goes in and it's something that we really want to get involved in and see what is happening there.
00:33:15 [W] Let's see what other questions are there.
00:33:20 [W] Can you please describe some of your other Disaster Recovery strategies?
00:33:28 [W] So Disaster Recovery needs to be like multifaceted.
00:33:32 [W] I don't think it's like only kubernative Centric, you know for us one of the big benefits and one of the big draws towards kubenetes is if we wanted to go to a hosted solution.
00:33:43 [W] It's really really easy, you know, this is did declarative infrastructure, you know, we've we've fully have like all of our all of our magalix.
00:33:51 [W] Jess what about Jung? Woo Templars ready for all of our services?
00:34:04 [W] So, you know something that we are exploring is what is the state of the world with eks and you know for that we can just spin up the exact same microservices that we are using in our current cabinet is infrastructure
00:34:11 [W] I'm with Nick Network policies and network plugins.
00:34:18 [W] There might be some I like underlying infrastructure things that go on under the hood, but like all of this, you know, as a big disaster mitigation strategy, we're not locked into any one particular Cloud vendor, you know, that's one of the massive jaws of system by
00:34:30 [W] previous setup in Mesa, Saint Martha
00:34:34 [W] What tooling do use for provisioning communities clusters and so when we started with communities there was no tooling available you'd go to the the readme page. There was no kubernative the hard way there was pretty pretty much nothing.
00:34:50 [W] We had to build a lot of the tooling from scratch and we've been able to iterate on that over time.
00:34:57 [W] time. So, you know right now we're running a coral s flatcar the next and with Cloud initiative and an ignition.
00:35:04 [W] We found this to be a really suitable way to spin up our community's infrastructure. If we were going to do the same today.
00:35:13 [W] We would not be utilizing any of that.
00:35:18 [W] There are plenty of excellent solutions to bootstrap pastors, like on any card provider or any on-premise infrastructure and we will automatically be looking into into some of those because they're going to give you a production ready set up
00:35:29 [W] Had to build over time.
00:35:36 [W] I would I would say that are set up is that perfectly fit for purpose for us?
00:35:40 [W] Whereas the the tools that are provided in the open source community that we've been following as well.
00:35:45 [W] I've been taking learnings from like production-ready no matter what scale that what scale you want to go to and you can get like a production ready set up with with good defaults and sensible configuration.
00:35:57 [W] And for us that's something that we'd really want to prioritize if we were going to spin up from scratch.
00:36:13 [W] So yeah, that's something that in the future if we if we want to like deprioritize running around clusters.
00:36:17 [W] It's something that we would be migrating onto the existing tooling for for self-hosting communities Cutters when we want to do some of the experimentation site.
00:36:27 [W] So with so many microservices are how do you tackle the problem of local development?
00:36:34 [W] So not entirely communities related, but I'll answer it nonetheless.
00:36:46 [W] One of the big benefits of having a Microsoft infrastructure is not every component needs to talk to every other component when engine is are developing locally.
00:36:50 [W] They don't need to spin up all 1600 plus components.
00:36:52 [W] We have automated tooling and a unified architecture in how we do our PCS.
00:36:57 [W] For example, if an engineer is spinning up service and it needs it has a dependency on another service because we use a go under the hood and go compilation times are really fast. We can just block the request for for
00:37:12 [W] And compile that that other Microsoft is a dependency and start it up all within a couple of seconds.
00:37:25 [W] So we have Dynamic tooling which can dynamically spin up microservices as engine is are developing.
00:37:28 [W] So yeah, and also Flows In very quiet very nicely into question that was asked what language are our microservices developed in all of our Microsoft Azure in go we found go to be like a really highly productive language
00:37:41 [W] typed first compilation times and you know for us running on on kubernetes, you know our goal microservices you can give them like 10 100 Milli cause of CPU and the you know, tens of megabytes of ram
00:37:56 [W] Ben pack really a lot of microservices on a single node, you know, we run nodes with 8v cause and 16 gigs of RAM and we're running like a 90 to 100 copies of different microservices on them.
00:38:12 [W] Because and 16 gigs of RAM and we're running like 90 to 100 copies of different microservices on the yeah.
00:38:19 [W] I think I've pretty much answered the vast majority that were asked in the in the QA slides will be shared.
00:38:28 [W] I'll share them on the on the slack Channel and yeah, like if you have any other questions, please feel free to ask on slack. I'll be happy to answer them.
