Kubeflow 1.0 Update by a Kubeflow Community Product Manager: GOQH-1387 - events@cncf.io - Thursday, August 20, 2020 8:28 AM - 369 minutes

Participant: wordly [W] English (US)

Transcription for wordly [W]

00:02:02 [W] Alright hello and welcome to our kubeflow update.
00:02:08 [W] Thank you for joining and being at kubevirt.
00:02:21 [W] in our kubeflow update today, we will go over kubeflow 1.0 and then we'll give a brief update on what's coming in kubeflow 1.1 will show a short demo
00:02:38 [W] Workflow in kubeflow and then we'll discuss about what's coming after kubeflow 1.1 and how to get involved with kubeflow community.
00:02:50 [W] So the kubeflow mission statement is a place that I like to start from kubeflow is designed to make it easy for everyone to develop deploy and manage a portable distributed and scalable
00:03:06 [W] On kubeflow on kubernative. So that's a mouthful. Let's try to break that down a bit develop deploy and manage you can think of that is I want to be able to develop a machine learning model in
00:03:22 [W] Book and then I'd like to be able to train tune and deploy that into production and have the tools to manage it.
00:03:31 [W] The ability to have it portable distributed and scalable portable.
00:03:37 [W] Meaning that I may want to have the same environment be able to work on my laptop on-prem in a larger cluster and then also in a public Cloud environment distributed
00:03:51 [W] Don't of machine learning at times you're going to want to use your infrastructure as effectively as possible.
00:04:02 [W] So you may have multiple nodes.
00:04:04 [W] You may have different capabilities on those nodes where you have gpus or CPUs or lots of ram you want to make sure that you're placing your workloads appropriately in a distributed way and then finally scalable where you
00:04:17 [W] down to a single node or up to hundreds or even thousands of gpus or CPUs as well as gigabytes of storage or lots of ram as well petabyte-scale storage actually
00:04:33 [W] MLS system on kubernative. So the important thing there is the ability to use kubernative effectively and the declarative operations, which allow you to leverage your infrastructure effectively
00:04:48 [W] Position as well as to minimize the operational overhead for the people that are managed that infrastructure.
00:04:58 [W] So this is the same mission that we've had since 2017 and we continue to deliver on it through the last 11 releases.
00:05:09 [W] Kubeflow is a collection of many different software components that allow you to build train and deploy a model.
00:05:24 [W] Let's walk through some of those components first.
00:05:26 [W] You have the jupyter notebook which provides that IDE experience.
00:05:33 [W] that is an interactive tool that allows you to teach and share your work effectively many people really
00:05:40 [W] Jupyter, notebooks one thing that's special about kubeflow.
00:05:45 [W] Jupyter.
00:05:52 [W] Notebooks is that they are you do have isolation for them and authentication.
00:05:56 [W] So users are separated from each other or they could share the same kubernative namespace.
00:06:04 [W] So you get the best of both worlds there when it comes to isolation and authentication training operators are important because inside of
00:06:10 [W] Of your mlperf Aang algorithms such as tensorflow pie torch or XG boost or MX net.
00:06:24 [W] You will have the MLA ER the machine learning layer that has Masters or workers or parameter servers and workers.
00:06:30 [W] Those have to be mapped into kubernative.
00:06:32 [W] He's Master workers and since any of those can be moving at any one time any of the workers could be moving.
00:06:39 [W] In / kubernetes, you need an operator a kubernative crg. Basically that will move those workloads to the appropriate place at the appropriate time.
00:06:55 [W] Those are all delivered as part of kubeflow. And it really does allow you to have distributed training which speeds up your model processing time workflow building.
00:07:05 [W] These are tools that allow you to simplify the way that you build a kubeflow pipeline and deploy it in run it.
00:07:09 [W] So typically in a kubeflow pipeline you have to build a containerized step for every pipeline step and then you have to write some kubeflow DSL
00:07:24 [W] Line step and then you have to write some kubeflow DSL domain specific language to run those those containers in the appropriate order kale and
00:07:33 [W] Errors in the appropriate order kale and fairing Basic Police simplify that process for you and make it go very much faster saving the data scientist quite a bit of time
00:07:42 [W] For you and make it go very much faster saving the data scientist quite a bit of time. Kubeflow pipelines is a way to schedule run and monitor
00:07:51 [W] Flow that will run your machine learning model. So from time to time, you're going to have your machine learning model and it will be receiving either new code or new data and rather than
00:08:07 [W] And rather than building Again by hand, it's good to have a workflow that does that for you kubeflow pipelines does that for you and then allows you to schedule how that's run to run it and then monitor effectively
00:08:21 [W] all how that's run to run it and then monitor effectively data management is below the container storage interface on kubeflow pipe below kubeflow, but it
00:08:31 [W] 12 but it does provide the versioning the sharing and the reproducibility that all have been very popular and a basic filled building block in order to do data science.
00:08:44 [W] science. You need to have a good data management layer. The tools involved the hyper parameter tuning the HP tuning the 10th circuit board and the Prometheus give you tuning allows you to take those hyperparameters.
00:09:00 [W] It's and adjust them appropriately automatically through a series of algorithms which saves you a bunch of time and make sure your your model run faster and more efficiently and more.
00:09:14 [W] Temps aboard gives you a visit visualization of your data and your code and then Prometheus allows you to have that infrastructure monitoring that allows you to better serve the at the software layer below the machine learning
00:09:30 [W] Layer, the metadata very important layer that allows you to keep the artifacts and the parameters there outside of the code the MLK code and the data in a way that
00:09:45 [W] Reproduce your model and understand what's necessary to have that model capable for you in a future time or reproducible and a future time and then finally KF serving these
00:10:01 [W] capable for you in a future time or reproducible and a future time and then finally KF serving these serving tools which we have three here KF serving seldom coredns TF serving allow
00:10:08 [W] Rules which we have three here KF serving seldom coredns TF serving allow you to put your model into production consistently and efficiently Selden coredns TF surveying or other much more mature
00:10:16 [W] Opponents KF serving or kubeflow serving is working to provide a simple interface for model serving and provide with as few as seven lines of.
00:10:30 [W] Yeah mlops.
00:10:47 [W] so that you can start with the simple configuration and add Advanced security and load balancing KF serving is designed from the ground up to speed model introduction with a be testing canaries and auto scaling
00:11:02 [W] Actually boost or others KF serving is built on top of St. O and K native so that you can start with a simple configuration and add Advanced security and load balancing KF serving is designed from the ground up
00:11:04 [W] The kubeflow serving components are designed to leverage kubernative sufficiently to utilize infrastructure resources in declarative operations to minimize your manual operations.
00:11:18 [W] So that's a quick look at the components inside of kubeflow.
00:11:22 [W] Let's continue down our path and look at what happened with kubeflow 1.0.
00:11:32 [W] So kubeflow 1.0 was RH release. It was delivered in March of 2020 as
00:11:33 [W] as important of all the software deliveries that we did which there were almost 200 issues that were delivered to improve the fit and finish was the process that the community agreed upon one
00:11:48 [W] Publish a kubeflow roadmap which defines the features and timing for releases.
00:12:00 [W] We also have a version in policy which defines the maturity of the components table beta or Alpha.
00:12:04 [W] We have delivered a stable applications requirement guide and in this guide it talks about what each components should address in order to become stable.
00:12:16 [W] Like configuration and deployment custom resources logging and monitoring Docker image ci/cd the documentation ownership and maintenance as well as user adoption.
00:12:31 [W] So in order to become stable, there is a checklist of things that each of the components should go through before they can claim to be stable.
00:12:40 [W] And then finally we track everything in a GitHub kanban board which are available for folks to get to these are all click through links that you can use.
00:12:46 [W] Inside of 1.0.
00:12:51 [W] We've delivered these stable components now Central dashboard the KF cuddle, which is the command line.
00:12:59 [W] Also the profile controller notebooks TF serving training operators both for tensorflow and pie charts as well as the documentation.
00:13:11 [W] There are many components in the beta level and they're all many of them are maturing and we'll talk about those as we get to 1.1.
00:13:16 [W] So that is a little bit on process that occurred it kubeflow in 1.0 and I think the next probably six or seven slides I'll go through quickly, but I wanted to give a feeling of who and why and what metrics
00:13:31 [W] Going to measure their success with kubeflow.
00:13:37 [W] So when we look at the kubeflow 1.0 testimonials many of these folks here are newer users to kubeflow, but they're getting good benefits out of it and you can see whether it's Dyson or US Bank or one Technologies are grouped by or Volvo that we've got
00:13:50 [W] You can see whether it's Dyson or US Bank or one Technologies are grouped by or Volvo that we've got a broad range of customers in different industries of different sizes, which is really interesting as a community because
00:13:58 [W] she's really interesting as a community because we get different kind of perspectives of what we should do as a product management people think about things differently, but when we also look at the success that the folks are having so
00:14:10 [W] Look at the success that the folks are having so Dyson saying they're expedite ideas from the lab to the bedside three times faster or US Bank deliver material productivity enhancements.
00:14:22 [W] one technology present the right product to the right customer at the right time or group by simplify very complicated deployments and then in Volvo to be able to iterate and produce with
00:14:35 [W] We a very good set of I guess comments from folks.
00:14:51 [W] Most of these folks have not been you know with us since 2017 and many of them probably in the last six months have deployed in God benefits out of kubeflow.
00:14:56 [W] So this is this is great news for folks that are coming in in more recent times, right? And so kubeflow one of the things I do as a product manager as I take
00:15:06 [W] Take a survey about every 90 to 180 days of the users this survey for 1.0 was the largest one.
00:15:17 [W] We had we had about a hundred and twenty people respond on, you know, at maximum this one we ask what best describes your roles and you can see machine learning Engineers are driving a lot of the comments and some of our
00:15:29 [W] About every ninety to a hundred eighty days of the users this survey for 1.0 was the largest one. We had we had about a hundred and twenty people respond on maximum this one we asked what
00:15:31 [W] User base at about 29 percent about 23% from data scientists and about 17% from software engineers and a smattering of other people but it's good to know what the roles are of the folks that are coming in asking
00:15:45 [W] Smattering of other people, but it's good to know what the roles are of the folks that are coming in asking for either creating issues or asking for features.
00:15:54 [W] The other is how many people work in your organization and you can see, you know about of large percentage here with more than 5,000 people but almost 20% from 51 to 500 so you have kind of this difference
00:16:04 [W] I've kind of this difference of maybe an Enterprise type customer and then our second biggest set of users being this group, which is more I would call a disruptor base and you know their capabilities
00:16:17 [W] Maybe the same but at times they may be different and how many data scientist in your organization so you can see here that almost 50% of the organizations have less than ten people. But again you have some
00:16:34 [W] And that have over a hundred data scientist.
00:16:42 [W] So if you have 10 data signs this or less your needs may be a little bit different than if you have a hundred data scientist.
00:16:46 [W] And then how do you use kubeflow in your in your company 24% just learning 21% or planning to use a growing percent here at 30% or using it into in development and 16% in production.
00:17:01 [W] A great numbers were really happy to see that progression. Now, we're going to get into a couple slides on the metrics that you can use to kind of measure where you stand with your machine learning this one talks about how long
00:17:17 [W] Valve one model from idea to production and you can see there's about 14 percent of the people it takes six months, but 30% it takes about a quarter and 25% takes a month these guys that are
00:17:33 [W] About a month. That's may be Best in Class not all models are the same but it's good to know that if you want to produce a model, how long does it take to produce it from idea to production in if you can do it in a month that you're in with some of the best in class.
00:17:48 [W] To produce it from idea to production and if you can do it in a month that you're in with some of the best in class metrics that are out there today.
00:17:55 [W] And then how many models has your team developed in the last six months?
00:17:58 [W] You can see here that you know about 34% have done 225 which means you know less than one model a month, but you've got 11 percent that have done over 50
00:18:10 [W] Over 50 models. So we do know that there's folks that join kubeflow earlier and they have become more efficient with it.
00:18:24 [W] And I think that's some of the value of being an early adopter is perhaps you get to be in this best-in-class group that's able to get the most out of kubeflow. And then how often do you deploy models into production and you can see here
00:18:33 [W] Early adopter is perhaps you get to be in this best-in-class group that's able to get the most out of kubeflow.
00:18:35 [W] And then how often do you deploy models into production and you can see here again every quarter about 21% every month about 22 or 23 percent and about
00:18:42 [W] Every quarter about 21% every month about 22 or 23 percent and about 18% or able to do it every week.
00:18:45 [W] I talk to a customer just the other day who said that they wanted to deploy models into production every day.
00:18:57 [W] every day. So I think we're driving in the right direction, and the model is helping people, and I thought this this feedback would be good for folks to see and then just looking at kubeflow versus non kubeflow so weaveworks.
00:19:04 [W] We have this question and we did allow non kubeflow users in the survey and you can see that kubeflow users all that hoo-ha.
00:19:16 [W] So this is users that have deployed more developed more than 20 models.
00:19:21 [W] So these would be probably your Best in Class users.
00:19:24 [W] You can see that more kubeflow users have developed models faster when one month the non kubeflow users the same for those that did in three months so the kind of
00:19:34 [W] Idea here is that the more that you have developing faster, probably the better and that's what it seems like kubeflow is doing from from this analysis again.
00:19:49 [W] Not not that this is the end all be all but it's a data point and probably the best data point that we have in the market right now.
00:19:54 [W] Another study Point here is what's that storage function a letí's are required for an AI and mly workloads and what you can analyze is that versioning and model sharing
00:20:10 [W] Two of the most important components which makes sense, right? If you have data data science, it's based on data management.
00:20:23 [W] You want to be able to version your models you need to be able to share your models and portability still very respectable at 43% I would just say we've been doing kubeflow surveys for several, you know
00:20:34 [W] Year and a half two years.
00:20:36 [W] I think it is. Now.
00:20:49 [W] This is the highest of any question we've ever had anything over 80% is really high for the community to be able to respond to so, I think it's something that folks do want to take a look at one of the important things
00:20:52 [W] I did do inside of kubeflow is to give an end to end user experience.
00:21:01 [W] So the tools that provide this as I talked about before one of them is called fairing fairing allows you to develop build train and deploy your models more efficiently using the Jupiter lab notebook
00:21:13 [W] And as well as the job seared he's as well as and kubeflow serving.
00:21:24 [W] So this does provide you for an effective way to build and deploy build train and deploy your models into production another CJ.
00:21:33 [W] That is an ecosystem. CJ is the kale.
00:21:35 [W] of you J also known as the notebooks. The pipeline's huge a you can develop create a pipeline run it and explore the pipeline later.
00:21:43 [W] ER using Jupiter kale and rock as well as kubeflow pipelines and rock to do some more exploration will go through a quick demo of this a little bit later.
00:21:58 [W] But the the real thing that I think folks get excited about when they look at this is that with these huge as you're able to reduce the number of steps necessary to deliver a model and so when you look
00:22:09 [W] Steps before having this capability it would take you twenty four steps maybe hundreds of hours.
00:22:24 [W] And you might say really it's going to take me hundreds of hours. But in each time that you're building a pipeline, you need to have the data scientist write the code and then they'll hand and code off to a data engineer or two.
00:22:31 [W] You need to have the data scientist write the code and then they'll hand and code off to a data engineer or 2. Mln.
00:22:33 [W] Janee R and probably an MLA engineer and the animal engineer will then take that code put it into a container put that container into a repo right some pipe lines DSL code and then try to make sure
00:22:47 [W] And then try to make sure that that pipeline will run effectively with the new tools with the touch of a button the data scientist doesn't have to know anything about kubernative use Docker or kubeflow
00:22:59 [W] All done for them automagically and we'll give that in a demo here in just a sec. So this demo we'll talk about how we know we annotate cells in them in a model will snap shot. The
00:23:14 [W] Wine will train it and we'll run the mro then we'll review the results and examine a pipeline step and iterate further.
00:23:30 [W] I know this is a lot but the iterate further is actually very very important in inside of data science because it will help you to make better models faster.
00:23:36 [W] So now I'm going to go over and do a screen share this may take me a second to get this up and running.
00:23:41 [W] And I will go into a platform here.
00:23:47 [W] Hopefully you can see my screen and I'm in a Marketplace which you can see from gcp this particular environment will also run
00:24:01 [W] In on your laptop, but there's an easy-to-use get started program called minikube f that's had thousands actually probably close to 15,000 users at this point.
00:24:19 [W] It's easy to use you can see how I'm setting it up in the gcp platform. So if you have a gcp account, you can see how many clicks I've had to do to get to a place where now I can click this and deploy it in about 20 minutes this whole environment
00:24:31 [W] Down there a couple clicks, it'll come up and I will end up with an environment that looks like this right.
00:24:40 [W] So this is the kubeflow central dashboard before I get to this. I will have to enter in a username and password that whole system for username and password for authentication can be integrated in with your ldap and AD
00:24:54 [W] Manse using is Theo indexed and many popes have have done that integration to this point.
00:25:02 [W] You'll also see that there is a namespace here.
00:25:08 [W] This is a kubernative namespace which keeps these folks isolated.
00:25:17 [W] So when I login I can either choose a namespace that is only to me or I can pick one that I share with other data scientists over on this side over here. You can see those components that we talked about the pipeline.
00:25:25 [W] Use a namespace that is only to me or I can pick one that I share with other data scientists over on this side over here.
00:26:25 [W] You can see those components that we talked about the pipeline's component The Notebook server cat tip, which is the hyper parameter the artifact store. This is the meta data volumes manager as well as a snapshot store.
00:26:26 [W] Both for you, right from the system. You have the ability to set your CPU and RAM for this notebook server. So you can apply resources appropriately and then the workspace volumes.
00:26:40 [W] This is where you'll keep your work and you want to have the ability to keep your work in protect it so in this you have a workspace volume, which is for as you would think your code and then a data volume which would is where you would put your data we can call
00:26:53 [W] You can give it a size and amount path other things that are nice about kubeflow.
00:27:01 [W] Notebooks is the configuration capability. So it's easy to get to external data sources using Secrets or environmental variables. So you don't have to remember those and then setting up gpus or is also made easy from here you can
00:27:15 [W] Once I launch it and click another button.
00:27:21 [W] I will get you a screen that looks like this.
00:27:22 [W] okay, we're
00:27:27 [W] we're now in back coming into the Jupiter lab and you'll see here that the Jupiter lab has come up and you have the launcher screen that you're used to and you have your notebook your console.
00:27:43 [W] There we've gone in and worked to create to download some examples into this as well as some code.
00:27:59 [W] So these examples here you can see we have a volume called Data inside of data inside of what we've downloaded using. Our terminal is some examples and you can see them here and the one that
00:28:09 [W] You is called Titanic and as we bring this up, you can see that we have the Titanic machine learning model that predicts who will survive the Titanic passenger, which passengers.
00:28:25 [W] all survived the Titanic shipwreck
00:28:29 [W] So you're probably familiar with this is a very popular Kegel model and you've seen all these workflow steps before what's a little bit unique that we've delivered is that we
00:28:44 [W] A pipeline that will look I'll show you the the cooked cake and then we'll come back that will look like this right that will have a load data step will have a pre-processing step.
00:29:00 [W] We'll do some feature engineering and then we'll go through all these other machine learning algorithms which will be trained tested and then deployed and used and then we'll get some results
00:29:13 [W] We have so we'll go back to the Jupiter lab now and show how we can easily create those steps in using this code that we've developed.
00:29:27 [W] So we'll turn on Kale which caled then allows us to identify the code that we want to be in our kubeflow pipeline steps.
00:29:37 [W] And we do that by annotating each cell over here. This first cell is a special Phil. It's called Imports so it won't be in our pipeline but it is important as we get started.
00:29:52 [W] Then we go to load data as you remember, you can see that this is a cell type pipeline step.
00:29:57 [W] It's called load data.
00:29:58 [W] It has no dependencies and you can see
00:30:10 [W] That that is a the first step in our kubeflow pipeline. Then some of these steps in your code as your data scientist will know they're interesting and you you want to look at this data, like for example, you may want to know that more
00:30:15 [W] The male's but it may not be something that you need as a kubeflow pipeline step.
00:30:26 [W] So you may skip a lot of those steps which allowed this allows you to do and then come to where you need to do some data pre-processing.
00:30:34 [W] So this may be your second step and again, you can see this is a pipeline step.
00:30:36 [W] It depends on load data and it has it's called Data pre-processing.
00:30:40 [W] So any code any code or any cell below data pre-processing that has the same color is going to be used in this step and built into the container that will automatically build in a few minutes.
00:30:55 [W] To do some data pre-processing.
00:30:57 [W] So this may be your second step and again, you can see this is a pipeline step.
00:30:57 [W] It depends on load data and it has its called Data pre-processing.
00:30:57 [W] So any code any code or any cell below data pre-processing that has the same color is going to be used in this step and built into the container that will automatically build in a few minutes.
00:30:59 [W] Can see as we process the data.
00:31:00 [W] We're going to get rid of some missing data.
00:31:04 [W] We're going to account for that and then we'll get the feature engineering feature engineering is another step that will be in our pipeline will do some changing some sex in two numeric or dropping some various features age in the
00:31:16 [W] Changing some sacks and two numeric or dropping some various features age in the category fairs in the category and then we get to the next steps which are all our machine learning code and are different models that
00:31:26 [W] And are different models that will run through and those will be based upon that feature engineering stepping done.
00:31:32 [W] And first we'll go through random Forest at the same time. We can be doing logistic regression The Bays svm decision tree and then the results will be based upon all this. So let's just say that we get to a point where we've got our code.
00:31:46 [W] And all are downloaded packages and libraries as well as our data into a good State and now we want to create a kubeflow pipeline instead of having to take that and break up all that code right Docker
00:32:01 [W] Them into a into a repo and then write the pipeline DSL code to run them. All we have to do is hit compile and run over here.
00:32:14 [W] And what tail will do with its back in snapshot and capability will take a snapshot of the environment.
00:32:25 [W] So these are all those persistent volumes that we used when we created The kubeflow Notebook and then it will create the pipeline. It will upload the pipeline and it will run the pipeline.
00:32:39 [W] So if we go and look at that, we can do a view of the of that pipeline being built here and this will take a few minutes for this pipeline to run but we will end up with a pipeline like
00:32:54 [W] You before and this is a representation of not just the sequential steps that are happening. But the data flows as when you're debugging you want to know what your inputs and
00:33:10 [W] Actually from a data perspective and so this particular pipeline will take a few minutes to run and why it's running.
00:33:26 [W] I just want to give kind of a shout out to the community.
00:33:28 [W] You know, I've been working in the kubeflow community for some time.
00:33:33 [W] I've met a lot of people. I know that the folks that are the vendor folks whether it's the Microsoft or Amazon Google or I bof
00:33:40 [W] BM become first-name basis with these folks and they do very interesting contributions.
00:33:48 [W] Whether it's David here on Checker Jeremy from Google or Amazon the folks there ginseng or the the other folks and a mesh from IBM Debo from Cisco very
00:34:02 [W] The organization but I think even more importantly is the contributions that we see from the users, right? So we have folks from
00:34:14 [W] Bloomberg dance on or from gojaks William Pinter or you know, you take Terry from Aunt Financial who are doing great contributions into the kubeflow community. And I think that's when you go to the kubeflow.
00:34:31 [W] Help share their stories so you can see at that. We built this model as we've gone through here that load data step that we talked about.
00:34:44 [W] We've got the data pre-processing the feature engineering and now we're at this machine learning layer, which this will take a little bit a bit of time because we're actually
00:34:58 [W] And training the models with some data and then we run through it again and we test it and then we actually run the model and see what our accuracy scores are and once those are all done.
00:35:13 [W] We sum all those up and put the results into a results tab, which we can then go in and look at and see what the results look like.
00:35:21 [W] They may be ready now in the interest of time. I'm going to try to click in and see if those artifacts are ready. I think I should probably wait a little bit until this.
00:35:29 [W] This step says it's done.
00:35:32 [W] But let's see if it's ready yet.
00:35:33 [W] Oh, there it is.
00:35:38 [W] So if I go into the results Tab and I look at the logs, you'll see here that although I think I might be smart.
00:35:48 [W] I may not be this Market each of my models came up with a hundred percent accuracy.
00:35:51 [W] So I know that maybe I did something wrong and now this is common and data science now, I want to go back in and potentially figure.
00:35:59 [W] Out what I did wrong so I can go into one of these steps.
00:36:04 [W] say the random forest and look at the artifacts that were created in this step. And in order to recreate that environment.
00:36:18 [W] I just click on that button as I did there. It takes me to my snapshots door which happens to be integrated with a system called Rock.
00:36:24 [W] I can copy this file link here.
00:36:25 [W] My notebook server and create a new notebook and say that I want to continue to keep exploring. I can autofill this call this random Forest.
00:36:44 [W] Easy for me to type and you can see I have my name space but all these other things the image the CPU and RAM the workspace the data volume all these have been pre filled in and I can launch this
00:37:00 [W] Few minutes.
00:37:02 [W] I'll bring up this random Forest step from my Pipeline and I will be able to continue to iterate on that step with all the data and all the code and all the downloaded packages.
00:37:17 [W] And I had when I first created this this iteration capability is very important to data scientists who often make some form of mistake or Challenge and then need to go back and improve their model.
00:37:33 [W] There's just new data comes in that they want to go through and take another look at and see how this impacts what they're doing. So you can see here as we go through.
00:37:48 [W] It's bringing up that notebook as we had and it will bring take me right to that random Forest step as you see and all my data that I was using.
00:37:59 [W] This is actually a clone of the data that I had so I can go ahead and start to use this I can mutate it and
00:38:03 [W] it impact the original snapshot but actually continue to keep iterating with that.
00:38:12 [W] I'm going to go back and finish up the that's the end of the presentation of the demonstration.
00:38:19 [W] I'll go back to excuse me, the the presentation and go back and just summarize what we saw. We annotated a notebook cells have the notebook of a model. We snapshot the environment. We built the pipeline
00:38:31 [W] in it, we reviewed the results and
00:38:36 [W] Then we examine the pipeline step and did further iteration.
00:39:37 [W] So this is good stuff, right? And now when we look at kubeflow 1.1, which is now based for delivery in Late July of 2020 what you'll see from the highlights is will have simplified
00:39:53 [W] Workflows. So we've got more fairing improvements that are coming along including the ability to set environmental variables and mount Secrets as well as the ability to
00:40:09 [W] Mapper in kale. We have a some workflows that incorporate the ability to use multi user pipelines and to tune a model efficiently and use cash steps.
00:40:24 [W] So as you're tuning a model will run through that model, maybe fifty a hundred times, maybe more in order to find the right hyper parameter settings for that model.
00:40:38 [W] You don't need to rerun all the steps of your model if you've already run them before in in-toto.
00:40:39 [W] In a kubeflow pipeline so you if you use the cached epsagon save processing time and save resources.
00:40:49 [W] Additionally we have stable training operators for MX net and XG boost.
00:40:53 [W] This is fantastic for folks, especially in the financial industry that use these types of algorithms and their models.
00:41:08 [W] We've improved the isolation and security again with multi-user pipelines, very popular request from folks private.
00:41:09 [W] G ke and Aunt those support cve scanning report so you can see the docker containers that are used to run kubeflow. You can see what the cves are there and then namespace creation
00:41:24 [W] - traitors rather the self-service bi administered by users.
00:41:31 [W] That's just something that Enterprise customers have asked for and we continue to help build that find it foundation for gitops installation and operations. And I think you'll see even more blueprint and kept hype integration as we
00:41:44 [W] And all this is tracked as you can see from the kubeflow 1.12 kanban board, which is available on this link.
00:41:55 [W] So what's next kubeflow Community governance is Big we're going to have plenty of workflow group working groups.
00:42:03 [W] that will be engaged and develop the working group is more what you consider a Sig and so we're in the process of defining that how that governance works and then kubeflow one.
00:42:15 [W] To and will be planned and started right after we got done with 1.1.
00:42:25 [W] So if you're interested in getting involved with kubeflow, please feel free to join in.
00:42:29 [W] We have a great slack Channel. We have a discussed mailing list that you can join we have weekly Community meetings every Tuesday and then you can use the slack Channel or submit bugs on GitHub
00:42:41 [W] Kubeflow repost we really wanted to give a big thank you to all the folks that have contributed to kubeflow at this point as well as all the users who either have contributed their time or effort as well as just given us
00:42:56 [W] Back, it's a great community and we welcome a lot of folks. You can see almost 25 percent of the folks that come to kubeflow community are new and that's been consistent since we started the community.
00:43:11 [W] thanks a lot for your time, and we look forward to your questions.
00:43:13 [W] Okay, I think that's the end of the presentation.
00:43:30 [W] definitely appreciate everybody listening. And as said before very excited to see the growth in kubeflow and to work with you.
